{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44334289",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b83a0386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, recall_score, confusion_matrix, classification_report, mean_squared_error, f1_score, accuracy_score, precision_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b69c6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the training dataset is (1102, 40), and the test one is (368, 40)\n",
      "percentage of attrition in Training is 16.1524500907441% and in test 16.032608695652176% \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = pd.read_csv('preprocessed_data.csv')\n",
    "data_no_encoding = pd.read_csv('preprocessed_data_no_categorical_encoding.csv')\n",
    "\n",
    "y = data['Attrition']\n",
    "\n",
    "X = data.drop('Attrition', axis = 1 )\n",
    "X_no_encoding = data_no_encoding.drop('Attrition', axis = 1)\n",
    "\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y , train_size= 0.75, random_state=42, stratify = y)\n",
    "#we make sure to do a stratified sampling because of the imbalanced dataset\n",
    "#Stratification does NOT fix imbalance, it only preserves it.\n",
    "X_no_encoding_train = X_no_encoding.loc[X_train.index]\n",
    "X_no_encoding_test = X_no_encoding.loc[X_test.index]\n",
    "\n",
    "\n",
    "\n",
    "print(f'the size of the training dataset is {X_train.shape}, and the test one is {X_test.shape}')\n",
    "\n",
    "print(f'percentage of attrition in Training is {100 * len(y_train[y_train==1])/len(y_train)}% and in test {100 * len(y_test[y_test==1])/len(y_test)}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08984744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = ['BusinessTravel','Education','EnvironmentSatisfaction','JobInvolvement',\n",
    "                'JobLevel','JobSatisfaction','PerformanceRating','RelationshipSatisfaction',\n",
    "                'StockOptionLevel','WorkLifeBalance', 'Department','EducationField','Gender',\n",
    "                'JobRole','MaritalStatus','OverTime']\n",
    "\n",
    "set(categorical_cols) <= set(X_no_encoding.columns) # simple verification that the ensemble of ordinal and nominal columns are actually present in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d93d7",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cfc528",
   "metadata": {},
   "source": [
    "We will go through a lot of models of classification, and organize the results in a dataFrame.\n",
    "\n",
    "For each model we'll try to retrieve as much info as possible.\n",
    "\n",
    "All models has be evaluated on the same data splits so comparisons are fair.\n",
    "\n",
    "The nexxt step after splitting data between training and test is to understand how each model behaves.\n",
    "\n",
    "This will be done by validation on the training data only first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6867b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Mean_AUC','Mean_F1','Mean_Precision','Mean_Recall', 'Mean_Accuracy'])\n",
    "\n",
    "scoring = {\n",
    "    \"auc\": \"roc_auc\",\n",
    "    \"f1\": \"f1\",\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"accuracy\": \"accuracy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d0d0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv  = StratifiedKFold(n_splits = 5 , shuffle= True , random_state= 425)\n",
    "#shuffle is true so data is shuffled before split and to protect in case data were ordered somehow by classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "162126c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidate(model_name, model, X_train, y_train, cross_info):\n",
    "\n",
    "    cv_results = cross_validate(\n",
    "        estimator=model,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        cv=cross_info,\n",
    "        scoring=scoring,\n",
    "    )\n",
    "\n",
    "    aggregated_metrics = [value.mean() for (key, value) in cv_results.items()]\n",
    "    results.loc[model_name] = aggregated_metrics[2:] # the first two values in the list corresponds to fit_time and score_time\n",
    "\n",
    "\"\"\"\n",
    "In logistic regression :\n",
    "    C = 1/λ (where λ is the regularization strength)\n",
    "    Inverse relationship: Smaller C means stronger regularization, larger C means weaker regularization\n",
    "\"\"\"\n",
    "\n",
    "models = {\n",
    "    'simple_logistic_regression' : LogisticRegression(C= np.inf, max_iter=1000, random_state=42),\n",
    "    'logistic_regression_lasso' : LogisticRegression(l1_ratio= 1 ,solver = 'liblinear', C = 1 , max_iter=1000, random_state=42), #the default solver lbfgs doesn't support l1 penalty\n",
    "    'logistic_regression_ridge' : LogisticRegression(l1_ratio= 0 , C = 1, max_iter=1000, random_state=42),\n",
    "    'logistic_elastic_net' :  LogisticRegression(l1_ratio=0.5, solver = 'saga', C=1,  max_iter= 1000, random_state=42), # only saga supports elasticnet\n",
    "    'K nearest neighbors' : KNeighborsClassifier(n_neighbors=7, weights ='distance'), #weights to distance to closer neighbors has more important vote than further ones\n",
    "    'SVM_gaussian_kernel' : SVC(kernel ='rbf', random_state=42),\n",
    "    'SVM_polynomial_kernel' : SVC(kernel='poly',random_state=42),\n",
    "    'SVM_linear_kernel' : SVC(kernel='linear',random_state=42),\n",
    "    'Decion_tree_gini' : DecisionTreeClassifier(criterion='gini', random_state=17), #gini impurity as criterion of purity in each node\n",
    "    'Decision_tree_entropy' :  DecisionTreeClassifier(criterion='entropy', random_state=17), #normally we shouldn't expect much difference but both of them are very instable anyway\n",
    "    'Random Forest' : RandomForestClassifier(random_state = 690),\n",
    "    'GradientBoosting' : GradientBoostingClassifier(loss = 'log_loss', n_estimators= 150, max_depth = 5),\n",
    "    'XGBoost' : XGBRFClassifier(),\n",
    "    'lightGBM' : LGBMClassifier(),\n",
    "        }\n",
    "\n",
    "# TODO I would have loved to use catboost as well because it can deal with datasets like plug and play\n",
    "# catboost can use categorical features without encoding , trees use subset of modalities when splitting\n",
    "# but unfortunatly there a version conflict causing the dollowing error : 'CatBoostClassifier' object has no attribute '__sklearn_tags__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eedb62dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1170: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1170: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1170: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1170: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1170: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 142, number of negative: 739\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1113\n",
      "[LightGBM] [Info] Number of data points in the train set: 881, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.161180 -> initscore=-1.649471\n",
      "[LightGBM] [Info] Start training from score -1.649471\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 142, number of negative: 739\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1110\n",
      "[LightGBM] [Info] Number of data points in the train set: 881, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.161180 -> initscore=-1.649471\n",
      "[LightGBM] [Info] Start training from score -1.649471\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 143, number of negative: 739\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 882, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.162132 -> initscore=-1.642453\n",
      "[LightGBM] [Info] Start training from score -1.642453\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 143, number of negative: 739\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1114\n",
      "[LightGBM] [Info] Number of data points in the train set: 882, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.162132 -> initscore=-1.642453\n",
      "[LightGBM] [Info] Start training from score -1.642453\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 142, number of negative: 740\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1112\n",
      "[LightGBM] [Info] Number of data points in the train set: 882, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160998 -> initscore=-1.650823\n",
      "[LightGBM] [Info] Start training from score -1.650823\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name , model in models.items() :\n",
    "    crossValidate(model_name, \n",
    "                  model, \n",
    "                  X_train, \n",
    "                  y_train, \n",
    "                  cv)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0193c39a",
   "metadata": {},
   "source": [
    "The table we can see above resumes the performance of each model via a cross validation of 5 splits\n",
    "\n",
    "However this was done to give us an idea on the performance of each model and in no case reflects the full abilities of the models that were tested as:\n",
    "\n",
    "    No HyperParameter tuning or Gridsearch was done to find the optimal parameters \n",
    "\n",
    "    Models haven't been tested on the test observations yet \n",
    "\n",
    "We'll class the models based on eachmetric and dive deep into the models depending on the metric we care more about "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d46979c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_AUC</th>\n",
       "      <th>Mean_F1</th>\n",
       "      <th>Mean_Precision</th>\n",
       "      <th>Mean_Recall</th>\n",
       "      <th>Mean_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple_logistic_regression</th>\n",
       "      <td>0.845945</td>\n",
       "      <td>0.597337</td>\n",
       "      <td>0.740985</td>\n",
       "      <td>0.506825</td>\n",
       "      <td>0.890243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_regression_lasso</th>\n",
       "      <td>0.847598</td>\n",
       "      <td>0.584464</td>\n",
       "      <td>0.766090</td>\n",
       "      <td>0.478889</td>\n",
       "      <td>0.891148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_regression_ridge</th>\n",
       "      <td>0.847781</td>\n",
       "      <td>0.584744</td>\n",
       "      <td>0.771537</td>\n",
       "      <td>0.479206</td>\n",
       "      <td>0.892061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_elastic_net</th>\n",
       "      <td>0.847624</td>\n",
       "      <td>0.576249</td>\n",
       "      <td>0.765281</td>\n",
       "      <td>0.467619</td>\n",
       "      <td>0.890239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K nearest neighbors</th>\n",
       "      <td>0.729879</td>\n",
       "      <td>0.242328</td>\n",
       "      <td>0.783636</td>\n",
       "      <td>0.146984</td>\n",
       "      <td>0.856639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_gaussian_kernel</th>\n",
       "      <td>0.849805</td>\n",
       "      <td>0.268713</td>\n",
       "      <td>0.842778</td>\n",
       "      <td>0.163492</td>\n",
       "      <td>0.859362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_polynomial_kernel</th>\n",
       "      <td>0.841771</td>\n",
       "      <td>0.402881</td>\n",
       "      <td>0.891414</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>0.875673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_linear_kernel</th>\n",
       "      <td>0.845566</td>\n",
       "      <td>0.574598</td>\n",
       "      <td>0.722358</td>\n",
       "      <td>0.484762</td>\n",
       "      <td>0.886610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decion_tree_gini</th>\n",
       "      <td>0.592436</td>\n",
       "      <td>0.316203</td>\n",
       "      <td>0.303828</td>\n",
       "      <td>0.332063</td>\n",
       "      <td>0.768601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_tree_entropy</th>\n",
       "      <td>0.593012</td>\n",
       "      <td>0.310356</td>\n",
       "      <td>0.328807</td>\n",
       "      <td>0.303968</td>\n",
       "      <td>0.788573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.801747</td>\n",
       "      <td>0.321583</td>\n",
       "      <td>0.832747</td>\n",
       "      <td>0.208413</td>\n",
       "      <td>0.862978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.799835</td>\n",
       "      <td>0.404692</td>\n",
       "      <td>0.609845</td>\n",
       "      <td>0.304127</td>\n",
       "      <td>0.856643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.788360</td>\n",
       "      <td>0.468323</td>\n",
       "      <td>0.584115</td>\n",
       "      <td>0.399365</td>\n",
       "      <td>0.853924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightGBM</th>\n",
       "      <td>0.810117</td>\n",
       "      <td>0.452397</td>\n",
       "      <td>0.712982</td>\n",
       "      <td>0.337778</td>\n",
       "      <td>0.871156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Mean_AUC   Mean_F1  Mean_Precision  Mean_Recall  \\\n",
       "simple_logistic_regression  0.845945  0.597337        0.740985     0.506825   \n",
       "logistic_regression_lasso   0.847598  0.584464        0.766090     0.478889   \n",
       "logistic_regression_ridge   0.847781  0.584744        0.771537     0.479206   \n",
       "logistic_elastic_net        0.847624  0.576249        0.765281     0.467619   \n",
       "K nearest neighbors         0.729879  0.242328        0.783636     0.146984   \n",
       "SVM_gaussian_kernel         0.849805  0.268713        0.842778     0.163492   \n",
       "SVM_polynomial_kernel       0.841771  0.402881        0.891414     0.269841   \n",
       "SVM_linear_kernel           0.845566  0.574598        0.722358     0.484762   \n",
       "Decion_tree_gini            0.592436  0.316203        0.303828     0.332063   \n",
       "Decision_tree_entropy       0.593012  0.310356        0.328807     0.303968   \n",
       "Random Forest               0.801747  0.321583        0.832747     0.208413   \n",
       "GradientBoosting            0.799835  0.404692        0.609845     0.304127   \n",
       "XGBoost                     0.788360  0.468323        0.584115     0.399365   \n",
       "lightGBM                    0.810117  0.452397        0.712982     0.337778   \n",
       "\n",
       "                            Mean_Accuracy  \n",
       "simple_logistic_regression       0.890243  \n",
       "logistic_regression_lasso        0.891148  \n",
       "logistic_regression_ridge        0.892061  \n",
       "logistic_elastic_net             0.890239  \n",
       "K nearest neighbors              0.856639  \n",
       "SVM_gaussian_kernel              0.859362  \n",
       "SVM_polynomial_kernel            0.875673  \n",
       "SVM_linear_kernel                0.886610  \n",
       "Decion_tree_gini                 0.768601  \n",
       "Decision_tree_entropy            0.788573  \n",
       "Random Forest                    0.862978  \n",
       "GradientBoosting                 0.856643  \n",
       "XGBoost                          0.853924  \n",
       "lightGBM                         0.871156  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d094627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "\n",
    "models = results.index.tolist()\n",
    "x = np.arange(len(models))\n",
    "\n",
    "for col in results.columns:\n",
    "    y = results[col].values\n",
    "    plt.plot(x, y, marker='o', label=col)\n",
    "\n",
    "    # 🔢 annotate values\n",
    "    for i, val in enumerate(y):\n",
    "        plt.text(\n",
    "            i, val,\n",
    "            f\"{val:.3f}\",\n",
    "            fontsize=12,\n",
    "            ha='center',\n",
    "            va='bottom'\n",
    "        )\n",
    "\n",
    "plt.xticks(x, models, rotation=45, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f9b39",
   "metadata": {},
   "source": [
    "All the metrics have some information to reflect , so we'll favorise models that excel in all of them  or the majority of them.\n",
    "\n",
    "However we do care also more about AUC since, as mentionned before , the datset is clearly imbalaced but also about Recall ( among all the the employees that truly left, how much did we correctly predict ).\n",
    "\n",
    "We do care a lot about recall, because it's really important to captivate all the employees before they churn \n",
    "\n",
    "With that being said we'll start with logistic regression , then Random Forest then SVM and last XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e8a87",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e911f697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average auc for 10 splits is 0.8522529005368705\n",
      "the average recall for 10 splits is 0.48692810457516333\n"
     ]
    }
   ],
   "source": [
    "Kfold = StratifiedKFold( n_splits=10, shuffle= True, random_state= 42)\n",
    "cross_metrics = cross_validate (estimator= LogisticRegression(max_iter=1000),\n",
    "                X= X_train, y = y_train, cv = Kfold,\n",
    "                  scoring=['roc_auc','recall'], )\n",
    "\n",
    "for metric in ['test_roc_auc', 'test_recall']:\n",
    "    print (f'the average {metric.split('_')[-1]} for 10 splits is {cross_metrics[metric].mean() }')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b28088d",
   "metadata": {},
   "source": [
    "Before this there is something really dangerous i didn't pay attention to : Data Leakage\n",
    "\n",
    "    Scaling/log transforms must be learned only from training folds ( we did EDA like Standard scaling of numerical variables using the entire datasets :(( )\n",
    "\n",
    "    Otherwise CV scores are optimistic\n",
    "\n",
    "AUC ≈ 0.85 → good separability\n",
    "\n",
    "Recall ≈ 0.49 → decision threshold issue, not necessarily model weakness\n",
    "\n",
    "This means:\n",
    "\n",
    "The model ranks employees well\n",
    "\n",
    "But the default threshold (0.5) is too conservative\n",
    "\n",
    "    GridSearch alone will not fully fix recall — threshold tuning will.\n",
    "\n",
    "    GridSearchCV systematically evaluates multiple combinations of hyperparameters using cross-validation and selects the combination that optimizes a chosen metric.\n",
    "\n",
    "What it is NOT\n",
    "\n",
    "     It does not “learn better features” !!!!!!\n",
    "\n",
    "     It does not fix a bad preprocessing pipeline !!!!!!\n",
    "\n",
    "     It does not change model assumptions !!!!!!\n",
    "\n",
    "GridSearch only answers:\n",
    "\n",
    "“Given this model family and this preprocessing, which configuration generalizes best under my metric?”\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8eee7f",
   "metadata": {},
   "source": [
    "Why no pipeline?\n",
    "\n",
    "For this exploratory phase, I fixed preprocessing to focus on model behavior and hyperparameter effects. \n",
    "\n",
    "I’m aware this introduces optimistic bias, so for final validation or deployment I would encapsulate all steps in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f633604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In grid search , here are the parameters that e care to explore, the rest will be kept as default \n",
    "\n",
    "parameters_grid = {\n",
    "    \"C\": np.logspace(-3, 2, 10), # 10 evenly space values between 1e-3 and 100\n",
    "    \"class_weight\": [None, \"balanced\"],\n",
    "    \"l1_ratio\": [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1]  # only used if elasticnet\n",
    "}\n",
    "\n",
    "best_performances = pd.DataFrame(columns = ['recall' , 'roc_auc', 'mse'])\n",
    "\n",
    "\n",
    "startified_Kfold = StratifiedKFold(n_splits= 10, shuffle= True, random_state= 42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator = LogisticRegression(max_iter=1000, random_state=42, solver= 'saga', penalty = 'elasticnet', n_jobs=-1), # saga supports all penalties\n",
    "    param_grid = parameters_grid,\n",
    "    scoring = 'recall',\n",
    "    cv = startified_Kfold,\n",
    "    return_train_score = True # this allow us to unspect overfitting\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "364e4e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-11.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-11.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(max_iter=1000, n_jobs=-1,\n",
       "                                          penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                                          solver=&#x27;saga&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e-03, 3.59381366e-03, 1.29154967e-02, 4.64158883e-02,\n",
       "       1.66810054e-01, 5.99484250e-01, 2.15443469e+00, 7.74263683e+00,\n",
       "       2.78255940e+01, 1.00000000e+02]),\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;l1_ratio&#x27;: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1]},\n",
       "             return_train_score=True, scoring=&#x27;recall&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">LogisticRegre...solver=&#x27;saga&#x27;)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;C&#x27;: array([1.0000...00000000e+02]), &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;], &#x27;l1_ratio&#x27;: [0, 0.1, ...]}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;recall&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">StratifiedKFo... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>estimator: LogisticRegression</div></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"estimator__\"><pre>LogisticRegression(max_iter=1000, n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                   random_state=42, solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"estimator__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;elasticnet&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
       "            dual\n",
       "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
       "            intercept_scaling\n",
       "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;saga&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-11');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(max_iter=1000, n_jobs=-1,\n",
       "                                          penalty='elasticnet', random_state=42,\n",
       "                                          solver='saga'),\n",
       "             param_grid={'C': array([1.00000000e-03, 3.59381366e-03, 1.29154967e-02, 4.64158883e-02,\n",
       "       1.66810054e-01, 5.99484250e-01, 2.15443469e+00, 7.74263683e+00,\n",
       "       2.78255940e+01, 1.00000000e+02]),\n",
       "                         'class_weight': [None, 'balanced'],\n",
       "                         'l1_ratio': [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1]},\n",
       "             return_train_score=True, scoring='recall')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c66bd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "/home/zakaria/projects/attrition_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-12.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-12.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-12 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-12 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-12 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-12 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-12 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-12 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(max_iter=1000, n_jobs=-1,\n",
       "                                          penalty=&#x27;elasticnet&#x27;, random_state=42,\n",
       "                                          solver=&#x27;saga&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e-03, 3.59381366e-03, 1.29154967e-02, 4.64158883e-02,\n",
       "       1.66810054e-01, 5.99484250e-01, 2.15443469e+00, 7.74263683e+00,\n",
       "       2.78255940e+01, 1.00000000e+02]),\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;l1_ratio&#x27;: [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1]},\n",
       "             return_train_score=True, scoring=&#x27;recall&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">LogisticRegre...solver=&#x27;saga&#x27;)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;C&#x27;: array([1.0000...00000000e+02]), &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;], &#x27;l1_ratio&#x27;: [0, 0.1, ...]}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;recall&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">StratifiedKFo... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>LogisticRegression(C=np.float64(0.046415888336127795), class_weight=&#x27;balanced&#x27;,\n",
       "                   l1_ratio=0.1, max_iter=1000, n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                   random_state=42, solver=&#x27;saga&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;elasticnet&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">np.float64(0....5888336127795)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
       "            dual\n",
       "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
       "            intercept_scaling\n",
       "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;saga&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-12');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=LogisticRegression(max_iter=1000, n_jobs=-1,\n",
       "                                          penalty='elasticnet', random_state=42,\n",
       "                                          solver='saga'),\n",
       "             param_grid={'C': array([1.00000000e-03, 3.59381366e-03, 1.29154967e-02, 4.64158883e-02,\n",
       "       1.66810054e-01, 5.99484250e-01, 2.15443469e+00, 7.74263683e+00,\n",
       "       2.78255940e+01, 1.00000000e+02]),\n",
       "                         'class_weight': [None, 'balanced'],\n",
       "                         'l1_ratio': [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1]},\n",
       "             return_train_score=True, scoring='recall')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fca3fb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the combination of parameters that maximize our metric are  {'C': np.float64(0.046415888336127795), 'class_weight': 'balanced', 'l1_ratio': 0.1}\n",
      "the recall value correspond to this optimization is  0.7637254901960786\n"
     ]
    }
   ],
   "source": [
    "print('the combination of parameters that maximize our metric are ', grid.best_params_)\n",
    "print('the recall value correspond to this optimization is ', grid.best_score_) #The mean cross-validated score on the TRAINING data, using the metric i chose (recall),averaged over all CV folds,for the best hyperparameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0fecfa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall, auc and mse  of best log_reg combination is is equal to [0.6949152542372882, 0.793538478415885, 0.20380434782608695] \n"
     ]
    }
   ],
   "source": [
    "# Now let's test our best model on test data \n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test) \n",
    "y_prob = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "recall_log_reg = recall_score(y_test,y_pred)\n",
    "roc_auc_log_reg = roc_auc_score( y_test, y_prob)\n",
    "mse_log_reg = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "#measure the performance\n",
    "print(f'The recall, auc and mse  of best log_reg combination is is equal to {[recall_log_reg,roc_auc_log_reg,mse_log_reg]} ')\n",
    "\n",
    "best_performances.loc['logistic regression'] = (recall_log_reg, roc_auc_log_reg, mse_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cb2d300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifictaion report looks like \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87       309\n",
      "           1       0.42      0.69      0.52        59\n",
      "\n",
      "    accuracy                           0.80       368\n",
      "   macro avg       0.68      0.76      0.70       368\n",
      "weighted avg       0.85      0.80      0.81       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('The classifictaion report looks like \\n', classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2fbbe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'Truth')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_mat_log_reg = pd.DataFrame(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "sns.heatmap(confusion_mat_log_reg, annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1930f",
   "metadata": {},
   "source": [
    "### Results analysis\n",
    "\n",
    "As mentioned before,the grid search doesn't make the features better or the model itself better. However it does try all the given combinations of parameters and find the one that maximize the scoring metric we chose, in our case its recall \n",
    "\n",
    "on the validation, our best estimator had an average RECALL of 0.76 which is really impressing since what we use as a benchmark for logistic regression was 0.48\n",
    "\n",
    "Tested on a dataset never seen before , we got a Recall = 0.69 , an AUC = 0.79 and an MSE = 0.2\n",
    "\n",
    "With that being said, I had to dive a bit deeper into these metrics using a classification report.\n",
    "\n",
    "the first two lines of the report shows the classical metrics depending on wether we're trying to predict the class 0 and 1.\n",
    "\n",
    "We can see a huge difference between the performance when we're trying to predict class 0 (Non churn ) VS class 1 ( churn ), this difference was expected since dataset is imbalance and current employees are dominant ( 84% ). but the difference is still high \n",
    "\n",
    "The macro and micro average are good because the mediocre performance on predicting class 1 is hidden by the low percentage of this category \n",
    "\n",
    "Still, in the confusion matrix , we cans see that among the class 1 ( employees that left ) : 41 were correctly predicted but 18 were not ( False negatives ), which give us a false negative rate of 18/(18+41) = 0.3 !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8bc8fa",
   "metadata": {},
   "source": [
    "### Threshold Tuning\n",
    "\n",
    "the default threshold for deciding classes is 0.5.\n",
    "\n",
    "Maybe this threshold is a bit harsh, let's try and lower it a bit and see its effect on the performances. \n",
    "\n",
    "Except we shouldn't fall in the trap of lowering it too much and thus predicting everything as churning and thus very little false negative \n",
    "\n",
    "But we'll be massacring the performance on the prediction of current employees, causing a very low accuracy and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "217802ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (custom threshold): 0.712\n",
      "f1 score is 0.418\n",
      "accuracy in this case is 0.682\n",
      "-------------------\n",
      "the classification report is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.68      0.78       309\n",
      "           1       0.30      0.71      0.42        59\n",
      "\n",
      "    accuracy                           0.68       368\n",
      "   macro avg       0.61      0.69      0.60       368\n",
      "weighted avg       0.82      0.68      0.72       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's try some threshold tuning \n",
    "\n",
    "threshold = 0.4 # example\n",
    "y_pred_custom = (y_prob >= threshold).astype(int)\n",
    "\n",
    "print(\"Recall (custom threshold): {:.3f}\".format(recall_score(y_test, y_pred_custom)))\n",
    "print('f1 score is {:.3f}'.format(f1_score(y_test,y_pred_custom)))\n",
    "print('accuracy in this case is {:.3f}'.format(accuracy_score(y_test, y_pred_custom)))\n",
    "print('-------------------')\n",
    "print('the classification report is \\n', classification_report(y_test,y_pred_custom))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26ecd9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = np.linspace(0.1,0.9,15)\n",
    "recalls_lg, precisions_lg = [], []\n",
    "for threshold_ in thresholds :\n",
    "    y_updated = (y_prob >= threshold_).astype(int)\n",
    "    recalls_lg.append(recall_score(y_test, y_updated))\n",
    "    precisions_lg.append(precision_score(y_test,y_updated))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(thresholds, recalls_lg, label = 'Recall' )\n",
    "plt.plot(thresholds,precisions_lg, label ='Precision')\n",
    "plt.xlabel('Thresholds')\n",
    "plt.ylabel('Metric')\n",
    "plt.title('Recall and precision tradeoff')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e196f6",
   "metadata": {},
   "source": [
    "We actually want to maximize both the metrics, where maximizing recall means minimizing False negatives and maximizing precision means minimizing False positives\n",
    "\n",
    "Although we do care more about false negatives since we can't afford losing precious employees, However this can't come at the cost of precision.\n",
    "\n",
    "The question is : How much can we sacrifice of precision to gain in Recall ? To answer this we should have in had the cost of losing an employee VS the cost of giving an employee that wasn't intending to leave a raise/gifts to convince him of staying  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46723f86",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The coefficients in logistic regression doesn't have the same interpretation as in linear regression as they represent log_odds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f798664a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.55073047])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(best_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "edaa0dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverTime                             2.653463\n",
       "BusinessTravel                       1.721767\n",
       "NumCompaniesWorked                   1.494435\n",
       "MaritalStatus_Single                 1.475247\n",
       "YearsSinceLastPromotion              1.442220\n",
       "JobRole_Laboratory Technician        1.379191\n",
       "DistanceFromHome                     1.290105\n",
       "JobRole_Sales Executive              1.169585\n",
       "Gender                               1.164237\n",
       "JobRole_Sales Representative         1.162412\n",
       "EducationField_Marketing             1.128352\n",
       "EducationField_Technical Degree      1.107205\n",
       "MonthlyRate                          1.043032\n",
       "PerformanceRating                    1.015613\n",
       "JobRole_Human Resources              1.000000\n",
       "JobRole_Manager                      1.000000\n",
       "JobRole_Manufacturing Director       0.989516\n",
       "MaritalStatus_Married                0.989509\n",
       "Education                            0.983444\n",
       "EducationField_Medical               0.946200\n",
       "HourlyRate                           0.929800\n",
       "EducationField_Other                 0.928156\n",
       "PercentSalaryHike                    0.923271\n",
       "EducationField_Life Sciences         0.902281\n",
       "JobRole_Research Director            0.894955\n",
       "TrainingTimesLastYear                0.876230\n",
       "YearsInCurrentRole                   0.875669\n",
       "DailyRate                            0.872924\n",
       "Age                                  0.831252\n",
       "MonthlyIncome                        0.806575\n",
       "WorkLifeBalance                      0.804774\n",
       "RelationshipSatisfaction             0.800672\n",
       "StockOptionLevel                     0.778730\n",
       "YearsWithCurrManager                 0.765824\n",
       "JobRole_Research Scientist           0.759541\n",
       "JobSatisfaction                      0.759205\n",
       "EnvironmentSatisfaction              0.731670\n",
       "JobInvolvement                       0.712529\n",
       "TotalWorkingYears                    0.678720\n",
       "Department_Research & Development    0.666137\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds = pd.Series(\n",
    "    np.exp(best_model.coef_[0]),\n",
    "    index=X_train.columns\n",
    ")\n",
    "\n",
    "odds.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42be9264",
   "metadata": {},
   "source": [
    "intercept correspond to the baseline odds of attrition when all features are 0\n",
    "\n",
    "for the rest of the coefficient ( they were stored in the same order as the columns )\n",
    "\n",
    "A coefficient βj means:\n",
    "\n",
    "    Change in log-odds for a one-unit increase in feature xj\n",
    "\n",
    "\n",
    "np.exp(coef) > 1 → increases odds of attrition\n",
    "\n",
    "np.exp(coef) < 1 → decreases odds\n",
    "\n",
    "Magnitude matters only because I you scaled features ( 1 unit = standard deviation across all features)\n",
    "\n",
    "---> Coefficient signs are always interpretable\n",
    "\n",
    "---> Coefficient magnitudes are only comparable across features that are on comparable scales\n",
    "\n",
    "Since our ordinal variables are not scaled, their coefficient magnitudes are not directly comparable to scaled numerical features.\n",
    "\n",
    "\n",
    "Now compare:\n",
    "\n",
    "Scaled numeric feature\n",
    "    \n",
    "    → +1 = 1 standard deviation\n",
    "\n",
    "Ordinal feature\n",
    "\n",
    "    → +1 = one category step (e.g. “Low → Medium”)\n",
    "\n",
    "These “+1” changes do not mean the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8b557",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b03b92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average auc for 10 splits is 0.8186125739839337\n",
      "the average 1 for 10 splits is 0.16895424836601308\n",
      "the average 1 for 10 splits is 0.8383333333333333\n"
     ]
    }
   ],
   "source": [
    "strat_Kfold_RF = StratifiedKFold(n_splits= 10, shuffle=True, random_state=42)\n",
    "\n",
    "scoring_dict = {\n",
    "    'recall_1' : 'recall', # we added one for the name of the metrics because it's the one of predicting class 1\n",
    "    'precision_1' : 'precision',\n",
    "    'roc_auc' : 'roc_auc'\n",
    "}\n",
    "\n",
    "cv_random_forest= cross_validate(\n",
    "    estimator=RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    X = X_train, y = y_train,\n",
    "    cv = strat_Kfold_RF ,\n",
    "    scoring = scoring_dict\n",
    ")\n",
    "\n",
    "\n",
    "for metric in ['test_roc_auc', 'test_recall_1','test_precision_1']:\n",
    "    print (f'the average {metric.split('_')[-1]} for 10 splits is {cv_random_forest[metric].mean() }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabc495a",
   "metadata": {},
   "source": [
    "In the example above, we can see the performance of the random forest algorithm on our data with default parameters.\n",
    "\n",
    "This is textbook Random Forest behavior on imbalanced data with default settings. Why?\n",
    "\n",
    "    RF optimizes node purity, not recall\n",
    "\n",
    "    Default threshold = 0.5\n",
    "\n",
    "    No class weighting by default\n",
    "\n",
    "    Trees are very confident → few positive predictions\n",
    "\n",
    "So low recall ≠ weak model\n",
    "\n",
    "The recall is awful ( 0.16 )!!!! , meaning on average , we catch only 16% of leavers among all the employees that were actually intending to leave.\n",
    "\n",
    "But to cut the model some slack we didn't tune a lot of parameters that can clearly improve the model's performance specially that we're dealing with an imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39733661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-18.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-18.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-18 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-18 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-18 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-18 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-18 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-18 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-18 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-18 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-18 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(n_estimators=200, n_jobs=4,\n",
       "                                              random_state=67),\n",
       "             param_grid={&#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 5, 10, 20],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 10, 30]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">RandomForestC...ndom_state=67)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;], &#x27;max_depth&#x27;: [None, 5, ...], &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, ...], &#x27;min_samples_leaf&#x27;: [1, 5, ...], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;recall&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">StratifiedKFo... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>estimator: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"estimator__\"><pre>RandomForestClassifier(n_estimators=200, n_jobs=4, random_state=67)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"estimator__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.<br>Note: This parameter is tree-specific.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D%22sqrt%22\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.accuracy_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">67</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=class_weight,-%7B%22balanced%22%2C%20%22balanced_subsample%22%7D%2C%20dict%20or%20list%20of%20dicts%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>The \"balanced_subsample\" mode is the same as \"balanced\" except that<br>weights are computed based on the bootstrap sample for every tree<br>grown.<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-18');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(n_estimators=200, n_jobs=4,\n",
       "                                              random_state=67),\n",
       "             param_grid={'class_weight': [None, 'balanced'],\n",
       "                         'max_depth': [None, 5, 10, 20],\n",
       "                         'max_features': [None, 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 5, 10],\n",
       "                         'min_samples_split': [2, 10, 30]},\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_RF = {\n",
    "    \"max_depth\": [None, 5, 10, 20], #The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split \n",
    "    \"min_samples_split\": [2, 10, 30], #The minimum number of samples required to split an internal node\n",
    "    \"min_samples_leaf\": [1, 5, 10], #The minimum number of samples required to be at a leaf node\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"], #The number of features to consider when looking for the best split, None corresponds to considering all features \n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "\n",
    "gridsearch_RF =GridSearchCV(\n",
    "    estimator= RandomForestClassifier(n_estimators=200, n_jobs=4, bootstrap=True, random_state=67), # six seveeeeeeeeeeeeeeen\n",
    "    param_grid=parameters_RF,\n",
    "    scoring= 'recall',\n",
    "    cv= strat_Kfold_RF,\n",
    "    verbose = 10\n",
    ")\n",
    "\n",
    "gridsearch_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "612ab217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 216 candidates, totalling 2160 fits\n",
      "[CV 1/10; 1/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 1/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 2/10; 1/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 1/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.333 total time=   0.7s\n",
      "[CV 3/10; 1/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 1/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.235 total time=   0.7s\n",
      "[CV 4/10; 1/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 1/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.294 total time=   0.8s\n",
      "[CV 5/10; 1/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 1/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.8s\n",
      "[CV 6/10; 1/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 1/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.8s\n",
      "[CV 7/10; 1/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 1/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 8/10; 1/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 1/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 9/10; 1/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 1/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 10/10; 1/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 1/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 1/10; 2/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 2/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 2/10; 2/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 2/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 3/10; 2/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 2/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.294 total time=   0.7s\n",
      "[CV 4/10; 2/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 2/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.353 total time=   0.8s\n",
      "[CV 5/10; 2/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 2/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 6/10; 2/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 2/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 7/10; 2/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 2/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 8/10; 2/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 2/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.8s\n",
      "[CV 9/10; 2/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 2/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 10/10; 2/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 2/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.7s\n",
      "[CV 1/10; 3/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 3/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.7s\n",
      "[CV 2/10; 3/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 3/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 3/10; 3/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 3/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.294 total time=   0.7s\n",
      "[CV 4/10; 3/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 3/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.294 total time=   0.9s\n",
      "[CV 5/10; 3/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 3/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.9s\n",
      "[CV 6/10; 3/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 3/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.8s\n",
      "[CV 7/10; 3/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 3/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 3/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 3/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 3/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 3/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 10/10; 3/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 3/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.8s\n",
      "[CV 1/10; 4/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 4/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.8s\n",
      "[CV 2/10; 4/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 4/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.8s\n",
      "[CV 3/10; 4/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 4/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.235 total time=   0.6s\n",
      "[CV 4/10; 4/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 4/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.294 total time=   0.8s\n",
      "[CV 5/10; 4/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 4/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 4/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 4/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 4/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 4/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 8/10; 4/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 4/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 4/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 4/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.8s\n",
      "[CV 10/10; 4/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 4/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 1/10; 5/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 5/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 2/10; 5/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 5/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 3/10; 5/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 5/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 4/10; 5/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 5/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.294 total time=   0.5s\n",
      "[CV 5/10; 5/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 5/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 5/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 5/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 5/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 5/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 5/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 5/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 5/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 5/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 5/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 5/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 6/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 6/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 6/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 6/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 3/10; 6/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 6/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.294 total time=   0.8s\n",
      "[CV 4/10; 6/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 6/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 6/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 6/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.8s\n",
      "[CV 6/10; 6/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 6/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 6/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 6/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 6/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 6/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 6/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 6/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 10/10; 6/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 6/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.7s\n",
      "[CV 1/10; 7/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 7/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.8s\n",
      "[CV 2/10; 7/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 7/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 3/10; 7/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 7/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.235 total time=   0.6s\n",
      "[CV 4/10; 7/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 7/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 7/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 7/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 6/10; 7/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 7/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 7/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 7/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 8/10; 7/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 7/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 7/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 7/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.278 total time=   0.8s\n",
      "[CV 10/10; 7/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 7/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 1/10; 8/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 8/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.7s\n",
      "[CV 2/10; 8/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 8/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 3/10; 8/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 8/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.235 total time=   0.7s\n",
      "[CV 4/10; 8/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 8/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.294 total time=   0.5s\n",
      "[CV 5/10; 8/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 8/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 8/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 8/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 8/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 8/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 8/10; 8/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 8/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.278 total time=   0.5s\n",
      "[CV 9/10; 8/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 8/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.278 total time=   0.5s\n",
      "[CV 10/10; 8/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 8/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 1/10; 9/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 9/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.5s\n",
      "[CV 2/10; 9/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 9/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 9/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 9/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.235 total time=   0.7s\n",
      "[CV 4/10; 9/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 9/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 9/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 9/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.7s\n",
      "[CV 6/10; 9/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 9/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 9/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 9/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 8/10; 9/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 9/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.278 total time=   0.8s\n",
      "[CV 9/10; 9/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 9/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 9/216] START class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 9/216] END class_weight=None, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.222 total time=   0.5s\n",
      "[CV 1/10; 10/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 10/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.9s\n",
      "[CV 2/10; 10/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 10/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.7s\n",
      "[CV 3/10; 10/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 10/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.7s\n",
      "[CV 4/10; 10/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 10/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.7s\n",
      "[CV 5/10; 10/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 10/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.056 total time=   0.7s\n",
      "[CV 6/10; 10/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 10/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.5s\n",
      "[CV 7/10; 10/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 10/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 8/10; 10/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 10/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 9/10; 10/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 10/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.8s\n",
      "[CV 10/10; 10/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 10/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.8s\n",
      "[CV 1/10; 11/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 11/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 11/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 11/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 11/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 11/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.118 total time=   0.7s\n",
      "[CV 4/10; 11/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 11/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.294 total time=   0.7s\n",
      "[CV 5/10; 11/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 11/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.7s\n",
      "[CV 6/10; 11/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 11/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 7/10; 11/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 11/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.8s\n",
      "[CV 8/10; 11/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 11/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 11/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 11/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 11/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 11/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.9s\n",
      "[CV 1/10; 12/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 12/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.8s\n",
      "[CV 2/10; 12/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 12/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.7s\n",
      "[CV 3/10; 12/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 12/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 12/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 12/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 12/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 12/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 12/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 12/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 12/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 12/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 8/10; 12/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 12/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 12/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 12/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.5s\n",
      "[CV 10/10; 12/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 12/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 13/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 13/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 13/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 13/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 3/10; 13/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 13/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.118 total time=   0.5s\n",
      "[CV 4/10; 13/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 13/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 13/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 13/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.056 total time=   0.5s\n",
      "[CV 6/10; 13/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 13/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 13/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 13/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 8/10; 13/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 13/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 13/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 13/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 10/10; 13/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 13/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 1/10; 14/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 14/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.5s\n",
      "[CV 2/10; 14/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 14/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.5s\n",
      "[CV 3/10; 14/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 14/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 14/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 14/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.235 total time=   0.5s\n",
      "[CV 5/10; 14/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 14/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.056 total time=   0.5s\n",
      "[CV 6/10; 14/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 14/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.5s\n",
      "[CV 7/10; 14/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 14/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.7s\n",
      "[CV 8/10; 14/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 14/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.8s\n",
      "[CV 9/10; 14/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 14/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 14/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 14/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.7s\n",
      "[CV 1/10; 15/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 15/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.7s\n",
      "[CV 2/10; 15/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 15/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 3/10; 15/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 15/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 15/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 15/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.118 total time=   0.7s\n",
      "[CV 5/10; 15/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 15/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 15/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 15/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 15/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 15/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 8/10; 15/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 15/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.5s\n",
      "[CV 9/10; 15/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 15/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 15/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 15/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 1/10; 16/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 16/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 2/10; 16/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 16/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.5s\n",
      "[CV 3/10; 16/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 16/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.059 total time=   0.5s\n",
      "[CV 4/10; 16/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 16/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.118 total time=   0.5s\n",
      "[CV 5/10; 16/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 16/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.000 total time=   0.5s\n",
      "[CV 6/10; 16/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 16/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 7/10; 16/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 16/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 8/10; 16/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 16/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.222 total time=   0.5s\n",
      "[CV 9/10; 16/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 16/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 10/10; 16/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 16/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.5s\n",
      "[CV 1/10; 17/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 17/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.5s\n",
      "[CV 2/10; 17/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 17/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.5s\n",
      "[CV 3/10; 17/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 17/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 17/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 17/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.118 total time=   0.7s\n",
      "[CV 5/10; 17/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 17/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 17/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 17/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 17/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 17/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 17/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 17/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 17/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 17/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.5s\n",
      "[CV 10/10; 17/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 17/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 18/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 18/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 18/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 18/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 3/10; 18/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 18/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 18/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 18/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 18/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 18/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 18/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 18/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 18/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 18/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.7s\n",
      "[CV 8/10; 18/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 18/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.7s\n",
      "[CV 9/10; 18/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 18/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.7s\n",
      "[CV 10/10; 18/216] START class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 18/216] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.7s\n",
      "[CV 1/10; 19/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 19/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 19/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 19/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 19/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 19/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.059 total time=   0.7s\n",
      "[CV 4/10; 19/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 19/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.8s\n",
      "[CV 5/10; 19/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 19/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 6/10; 19/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 19/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.5s\n",
      "[CV 7/10; 19/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 19/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 8/10; 19/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 19/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 19/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 19/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 19/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 19/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 20/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 20/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 20/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 20/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 20/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 20/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 20/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 20/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 20/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 20/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 20/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 20/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 20/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 20/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 20/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 20/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 9/10; 20/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 20/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.7s\n",
      "[CV 10/10; 20/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 20/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 21/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 21/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 2/10; 21/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 21/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 3/10; 21/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 21/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 21/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 21/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 21/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 21/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 21/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 21/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 21/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 21/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 21/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 21/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 21/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 21/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 21/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 21/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 22/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 22/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 22/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 22/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 22/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 22/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 22/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 22/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 22/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 22/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 22/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 22/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 22/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 22/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 22/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 22/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 22/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 22/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 22/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 22/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 23/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 23/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.5s\n",
      "[CV 2/10; 23/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 23/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 23/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 23/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 23/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 23/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 23/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 23/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 23/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 23/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 23/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 23/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 23/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 23/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 9/10; 23/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 23/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 23/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 23/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 24/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 24/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 24/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 24/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 24/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 24/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 24/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 24/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 24/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 24/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.000 total time=   0.5s\n",
      "[CV 6/10; 24/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 24/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 24/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 24/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 24/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 24/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 24/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 24/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 24/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 24/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 25/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 25/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 25/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 25/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 25/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 25/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 25/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 25/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 25/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 25/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 25/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 25/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 25/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 25/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 25/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 25/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 25/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 25/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 25/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 25/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 1/10; 26/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 26/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 26/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 26/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 26/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 26/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 26/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 26/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 26/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 26/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.000 total time=   0.5s\n",
      "[CV 6/10; 26/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 26/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 26/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 26/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 26/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 26/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 26/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 26/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 26/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 26/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 1/10; 27/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 27/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 2/10; 27/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 27/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 3/10; 27/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 27/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 27/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 27/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 27/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 27/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 27/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 27/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 27/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 27/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 8/10; 27/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 27/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 27/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 27/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 27/216] START class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 27/216] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 1/10; 28/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 28/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 2/10; 28/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 28/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 3/10; 28/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 28/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.235 total time=   0.7s\n",
      "[CV 4/10; 28/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 28/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.294 total time=   0.7s\n",
      "[CV 5/10; 28/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 28/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 28/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 28/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 7/10; 28/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 28/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 28/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 28/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 9/10; 28/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 28/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 10/10; 28/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 28/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 29/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 29/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 29/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 29/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 3/10; 29/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 29/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.294 total time=   0.6s\n",
      "[CV 4/10; 29/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 29/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 29/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 29/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 29/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 29/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.5s\n",
      "[CV 7/10; 29/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 29/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 29/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 29/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 9/10; 29/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 29/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 29/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 29/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 30/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 30/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.7s\n",
      "[CV 2/10; 30/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 30/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.7s\n",
      "[CV 3/10; 30/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 30/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.294 total time=   0.6s\n",
      "[CV 4/10; 30/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 30/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.294 total time=   0.5s\n",
      "[CV 5/10; 30/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 30/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 30/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 30/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 30/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 30/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 30/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 30/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 30/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 30/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 10/10; 30/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 30/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 31/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 31/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 2/10; 31/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 31/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 3/10; 31/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 31/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.176 total time=   0.5s\n",
      "[CV 4/10; 31/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 31/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 31/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 31/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 31/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 31/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 31/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 31/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 31/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 31/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 31/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 31/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.7s\n",
      "[CV 10/10; 31/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 31/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 32/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 32/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.7s\n",
      "[CV 2/10; 32/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 32/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 3/10; 32/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 32/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.176 total time=   0.6s\n",
      "[CV 4/10; 32/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 32/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.294 total time=   0.7s\n",
      "[CV 5/10; 32/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 32/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.7s\n",
      "[CV 6/10; 32/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 32/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 32/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 32/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 8/10; 32/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 32/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 32/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 32/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 32/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 32/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 33/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 33/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 33/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 33/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 3/10; 33/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 33/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.294 total time=   0.7s\n",
      "[CV 4/10; 33/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 33/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.294 total time=   0.7s\n",
      "[CV 5/10; 33/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 33/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 33/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 33/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 33/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 33/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.7s\n",
      "[CV 8/10; 33/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 33/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 33/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 33/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.7s\n",
      "[CV 10/10; 33/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 33/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.7s\n",
      "[CV 1/10; 34/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 34/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 34/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 34/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 3/10; 34/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 34/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.176 total time=   0.7s\n",
      "[CV 4/10; 34/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 34/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.235 total time=   0.7s\n",
      "[CV 5/10; 34/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 34/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 6/10; 34/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 34/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 34/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 34/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 34/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 34/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 34/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 34/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.278 total time=   0.7s\n",
      "[CV 10/10; 34/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 34/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.222 total time=   0.5s\n",
      "[CV 1/10; 35/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 35/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.7s\n",
      "[CV 2/10; 35/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 35/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 3/10; 35/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 35/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.176 total time=   0.6s\n",
      "[CV 4/10; 35/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 35/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 35/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 35/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 35/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 35/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 35/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 35/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 35/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 35/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 35/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 35/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 10/10; 35/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 35/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 1/10; 36/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 36/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.7s\n",
      "[CV 2/10; 36/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 36/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.7s\n",
      "[CV 3/10; 36/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 36/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.176 total time=   0.7s\n",
      "[CV 4/10; 36/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 36/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.294 total time=   0.7s\n",
      "[CV 5/10; 36/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 36/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 36/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 36/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 7/10; 36/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 36/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 8/10; 36/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 36/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 36/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 36/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.222 total time=   0.7s\n",
      "[CV 10/10; 36/216] START class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 36/216] END class_weight=None, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 37/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 37/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 37/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 37/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 37/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 37/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 37/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 37/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 37/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 37/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 37/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 37/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 37/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 37/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 37/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 37/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 37/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 37/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 10/10; 37/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 37/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.056 total time=   0.7s\n",
      "[CV 1/10; 38/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 38/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 38/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 38/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 38/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 38/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 38/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 38/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 38/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 38/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 38/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 38/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.5s\n",
      "[CV 7/10; 38/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 38/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 38/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 38/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 38/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 38/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 38/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 38/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 39/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 39/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.4s\n",
      "[CV 2/10; 39/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 39/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 39/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 39/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.059 total time=   0.5s\n",
      "[CV 4/10; 39/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 39/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 39/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 39/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 39/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 39/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 39/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 39/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 39/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 39/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 9/10; 39/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 39/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 39/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 39/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.056 total time=   0.5s\n",
      "[CV 1/10; 40/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 40/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 40/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 40/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 40/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 40/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 40/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 40/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 40/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 40/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 40/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 40/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 40/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 40/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 40/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 40/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 40/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 40/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 40/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 40/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 41/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 41/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 41/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 41/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 41/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 41/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 41/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 41/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 41/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 41/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 41/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 41/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 41/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 41/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 41/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 41/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 41/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 41/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 41/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 41/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.056 total time=   0.5s\n",
      "[CV 1/10; 42/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 42/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 42/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 42/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 42/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 42/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 42/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 42/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 42/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 42/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 42/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 42/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 42/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 42/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 8/10; 42/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 42/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 42/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 42/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 42/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 42/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 43/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 43/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 43/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 43/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 3/10; 43/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 43/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 43/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 43/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.118 total time=   0.5s\n",
      "[CV 5/10; 43/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 43/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 43/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 43/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 7/10; 43/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 43/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 43/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 43/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 43/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 43/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 43/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 43/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 44/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 44/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 44/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 44/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 3/10; 44/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 44/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 44/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 44/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 44/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 44/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 44/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 44/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 7/10; 44/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 44/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.5s\n",
      "[CV 8/10; 44/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 44/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 44/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 44/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.5s\n",
      "[CV 10/10; 44/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 44/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 45/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 45/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 45/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 45/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 3/10; 45/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 45/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 45/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 45/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.118 total time=   0.5s\n",
      "[CV 5/10; 45/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 45/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 45/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 45/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 45/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 45/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 8/10; 45/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 45/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 45/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 45/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 45/216] START class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 45/216] END class_weight=None, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 46/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 46/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 46/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 46/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 46/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 46/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 46/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 46/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 46/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 46/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 46/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 46/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 46/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 46/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 46/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 46/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 9/10; 46/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 46/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 46/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 46/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 1/10; 47/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 47/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 2/10; 47/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 47/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 47/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 47/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 47/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 47/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 47/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 47/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.000 total time=   0.5s\n",
      "[CV 6/10; 47/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 47/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 47/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 47/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 47/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 47/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 47/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 47/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 47/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 47/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 48/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 48/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 48/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 48/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 48/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 48/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 48/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 48/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 48/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 48/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 48/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 48/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 48/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 48/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 48/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 48/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.5s\n",
      "[CV 9/10; 48/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 48/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 48/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 48/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 1/10; 49/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 49/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 2/10; 49/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 49/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 49/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 49/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.059 total time=   0.5s\n",
      "[CV 4/10; 49/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 49/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.176 total time=   0.4s\n",
      "[CV 5/10; 49/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 49/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 49/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 49/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 49/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 49/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 49/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 49/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 9/10; 49/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 49/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 49/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 49/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 50/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 50/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 2/10; 50/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 50/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.5s\n",
      "[CV 3/10; 50/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 50/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 50/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 50/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 50/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 50/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 50/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 50/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 50/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 50/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 50/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 50/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 9/10; 50/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 50/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.5s\n",
      "[CV 10/10; 50/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 50/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 51/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 51/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 2/10; 51/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 51/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 51/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 51/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 51/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 51/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 51/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 51/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 51/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 51/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 7/10; 51/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 51/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 51/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 51/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 9/10; 51/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 51/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 51/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 51/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 1/10; 52/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 52/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 52/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 52/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 52/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 52/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 52/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 52/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 52/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 52/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 52/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 52/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 52/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 52/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 52/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 52/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 9/10; 52/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 52/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 52/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 52/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 1/10; 53/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 53/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 53/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 53/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 53/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 53/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 53/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 53/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 53/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 53/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 53/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 53/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 53/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 53/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 53/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 53/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 9/10; 53/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 53/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 53/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 53/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 1/10; 54/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 54/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 2/10; 54/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 54/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 54/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 54/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.059 total time=   0.5s\n",
      "[CV 4/10; 54/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 54/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 54/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 54/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 54/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 54/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 7/10; 54/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 54/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 8/10; 54/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 54/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 9/10; 54/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 54/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 54/216] START class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 54/216] END class_weight=None, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.5s\n",
      "[CV 1/10; 55/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 55/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 2/10; 55/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 55/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 3/10; 55/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 55/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.294 total time=   0.6s\n",
      "[CV 4/10; 55/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 55/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.353 total time=   0.6s\n",
      "[CV 5/10; 55/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 55/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 6/10; 55/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 55/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 55/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 55/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 55/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 55/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 9/10; 55/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 55/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 10/10; 55/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 55/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 56/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 56/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 56/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 56/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 3/10; 56/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 56/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.294 total time=   0.6s\n",
      "[CV 4/10; 56/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 56/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 5/10; 56/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 56/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 6/10; 56/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 56/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 7/10; 56/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 56/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 56/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 56/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 56/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 56/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 10/10; 56/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 56/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 57/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 57/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 57/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 57/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 3/10; 57/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 57/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.294 total time=   0.6s\n",
      "[CV 4/10; 57/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 57/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 57/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 57/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 57/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 57/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 57/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 57/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 57/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 57/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 57/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 57/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 57/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 57/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.7s\n",
      "[CV 1/10; 58/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 58/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 2/10; 58/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 58/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 3/10; 58/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 58/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.235 total time=   0.6s\n",
      "[CV 4/10; 58/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 58/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 58/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 58/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 58/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 58/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 58/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 58/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 58/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 58/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 58/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 58/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 58/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 58/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 59/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 59/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 2/10; 59/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 59/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 3/10; 59/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 59/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 4/10; 59/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 59/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.294 total time=   0.5s\n",
      "[CV 5/10; 59/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 59/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 6/10; 59/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 59/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 59/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 59/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 8/10; 59/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 59/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 59/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 59/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 59/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 59/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 60/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 60/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 60/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 60/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 3/10; 60/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 60/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.294 total time=   0.6s\n",
      "[CV 4/10; 60/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 60/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 60/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 60/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 60/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 60/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.8s\n",
      "[CV 7/10; 60/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 60/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.7s\n",
      "[CV 8/10; 60/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 60/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 60/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 60/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.5s\n",
      "[CV 10/10; 60/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 60/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 61/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 61/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 61/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 61/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 3/10; 61/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 61/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.235 total time=   0.8s\n",
      "[CV 4/10; 61/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 61/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.294 total time=   0.7s\n",
      "[CV 5/10; 61/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 61/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 6/10; 61/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 61/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 61/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 61/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.222 total time=   0.8s\n",
      "[CV 8/10; 61/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 61/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.278 total time=   0.8s\n",
      "[CV 9/10; 61/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 61/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.278 total time=   0.7s\n",
      "[CV 10/10; 61/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 61/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 1/10; 62/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 62/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.7s\n",
      "[CV 2/10; 62/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 62/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.7s\n",
      "[CV 3/10; 62/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 62/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 4/10; 62/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 62/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.294 total time=   0.8s\n",
      "[CV 5/10; 62/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 62/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 62/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 62/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 62/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 62/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 62/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 62/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 62/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 62/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 62/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 62/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 1/10; 63/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 63/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.7s\n",
      "[CV 2/10; 63/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 63/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 63/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 63/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.235 total time=   0.6s\n",
      "[CV 4/10; 63/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 63/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.294 total time=   0.7s\n",
      "[CV 5/10; 63/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 63/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 63/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 63/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.8s\n",
      "[CV 7/10; 63/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 63/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 8/10; 63/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 63/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 63/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 63/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 63/216] START class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 63/216] END class_weight=None, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.222 total time=   0.7s\n",
      "[CV 1/10; 64/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 64/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 64/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 64/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 64/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 64/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 64/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 64/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 64/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 64/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 64/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 64/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 64/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 64/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 64/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 64/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 64/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 64/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 64/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 64/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 65/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 65/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 65/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 65/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.8s\n",
      "[CV 3/10; 65/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 65/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 65/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 65/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 65/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 65/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 65/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 65/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 65/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 65/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 65/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 65/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 65/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 65/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 65/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 65/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 66/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 66/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 66/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 66/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 66/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 66/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 66/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 66/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 66/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 66/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 66/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 66/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 66/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 66/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 66/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 66/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 66/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 66/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 66/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 66/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 67/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 67/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 2/10; 67/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 67/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 67/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 67/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 67/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 67/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 67/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 67/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 67/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 67/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 67/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 67/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 67/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 67/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.5s\n",
      "[CV 9/10; 67/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 67/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 67/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 67/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 68/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 68/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 68/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 68/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 68/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 68/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 68/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 68/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 68/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 68/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 68/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 68/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 68/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 68/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 68/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 68/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 68/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 68/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 68/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 68/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.4s\n",
      "[CV 1/10; 69/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 69/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 69/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 69/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 3/10; 69/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 69/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 69/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 69/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 69/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 69/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 69/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 69/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 69/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 69/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 69/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 69/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 69/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 69/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 69/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 69/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 70/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 70/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 70/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 70/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 3/10; 70/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 70/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 70/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 70/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 70/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 70/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.000 total time=   0.5s\n",
      "[CV 6/10; 70/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 70/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 70/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 70/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 70/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 70/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 70/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 70/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 70/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 70/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 71/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 71/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 71/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 71/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.5s\n",
      "[CV 3/10; 71/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 71/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 71/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 71/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 71/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 71/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 71/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 71/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 71/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 71/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 71/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 71/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 71/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 71/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 71/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 71/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 72/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 72/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 72/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 72/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 3/10; 72/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 72/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 72/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 72/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 72/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 72/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.5s\n",
      "[CV 6/10; 72/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 72/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 72/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 72/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 72/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 72/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 72/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 72/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 72/216] START class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 72/216] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 73/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 73/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 73/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 73/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 3/10; 73/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 73/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 73/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 73/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 73/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 73/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 73/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 73/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 73/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 73/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 73/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 73/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 73/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 73/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 73/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 73/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 74/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 74/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 74/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 74/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 74/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 74/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 74/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 74/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 74/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 74/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 74/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 74/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 74/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 74/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 74/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 74/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 74/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 74/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 74/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 74/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 75/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 75/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 75/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 75/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 3/10; 75/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 75/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 75/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 75/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 75/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 75/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 75/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 75/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 75/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 75/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 75/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 75/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 75/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 75/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 75/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 75/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 76/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 76/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 2/10; 76/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 76/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 76/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 76/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 76/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 76/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 76/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 76/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 76/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 76/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 7/10; 76/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 76/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 76/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 76/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 76/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 76/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 76/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 76/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 77/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 77/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 77/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 77/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 77/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 77/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.118 total time=   0.5s\n",
      "[CV 4/10; 77/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 77/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 77/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 77/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 77/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 77/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 77/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 77/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.8s\n",
      "[CV 8/10; 77/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 77/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 77/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 77/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 77/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 77/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 78/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 78/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 78/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 78/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 78/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 78/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 78/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 78/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 78/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 78/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 78/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 78/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 78/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 78/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 78/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 78/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 78/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 78/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 78/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 78/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 79/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 79/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 2/10; 79/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 79/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 3/10; 79/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 79/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.059 total time=   0.5s\n",
      "[CV 4/10; 79/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 79/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 79/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 79/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 79/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 79/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 79/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 79/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 79/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 79/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 79/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 79/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 79/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 79/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.000 total time=   0.5s\n",
      "[CV 1/10; 80/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 80/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 80/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 80/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 80/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 80/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 80/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 80/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 80/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 80/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 80/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 80/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 80/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 80/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.5s\n",
      "[CV 8/10; 80/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 80/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 80/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 80/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 80/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 80/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 1/10; 81/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 81/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 2/10; 81/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 81/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 81/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 81/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 4/10; 81/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 81/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.118 total time=   0.5s\n",
      "[CV 5/10; 81/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 81/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 81/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 81/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.8s\n",
      "[CV 7/10; 81/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 81/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 8/10; 81/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 81/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 81/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 81/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 81/216] START class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 81/216] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.5s\n",
      "[CV 1/10; 82/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 82/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 2/10; 82/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 82/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.333 total time=   0.7s\n",
      "[CV 3/10; 82/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 82/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.235 total time=   0.6s\n",
      "[CV 4/10; 82/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 82/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 82/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 82/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 82/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 82/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 82/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 82/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 82/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 82/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 82/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 82/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 10/10; 82/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 82/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 83/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 83/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 2/10; 83/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 83/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 3/10; 83/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 83/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.294 total time=   0.7s\n",
      "[CV 4/10; 83/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 83/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 5/10; 83/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 83/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 6/10; 83/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 83/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 83/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 83/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 83/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 83/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 9/10; 83/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 83/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 10/10; 83/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 83/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 84/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 84/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 84/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 84/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 3/10; 84/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 84/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.294 total time=   0.5s\n",
      "[CV 4/10; 84/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 84/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.294 total time=   0.7s\n",
      "[CV 5/10; 84/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 84/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.7s\n",
      "[CV 6/10; 84/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 84/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 84/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 84/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 84/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 84/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 84/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 84/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 10/10; 84/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 84/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 85/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 85/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 2/10; 85/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 85/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 3/10; 85/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 85/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.235 total time=   0.6s\n",
      "[CV 4/10; 85/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 85/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 85/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 85/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 85/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 85/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 85/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 85/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 85/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 85/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 85/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 85/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 85/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 85/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 86/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 86/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 2/10; 86/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 86/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 3/10; 86/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 86/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.235 total time=   0.7s\n",
      "[CV 4/10; 86/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 86/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 86/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 86/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 86/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 86/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 86/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 86/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 86/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 86/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 86/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 86/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 86/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 86/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 87/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 87/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 87/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 87/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.5s\n",
      "[CV 3/10; 87/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 87/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.294 total time=   0.6s\n",
      "[CV 4/10; 87/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 87/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 87/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 87/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 87/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 87/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 87/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 87/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 87/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 87/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 87/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 87/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.5s\n",
      "[CV 10/10; 87/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 87/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 88/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 88/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 88/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 88/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 3/10; 88/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 88/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.235 total time=   0.5s\n",
      "[CV 4/10; 88/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 88/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 88/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 88/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 6/10; 88/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 88/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 88/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 88/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 88/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 88/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 88/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 88/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 88/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 88/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 1/10; 89/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 89/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.5s\n",
      "[CV 2/10; 89/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 89/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 3/10; 89/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 89/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 4/10; 89/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 89/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 89/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 89/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 89/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 89/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.7s\n",
      "[CV 7/10; 89/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 89/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 89/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 89/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 9/10; 89/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 89/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.278 total time=   0.5s\n",
      "[CV 10/10; 89/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 89/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 1/10; 90/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 90/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.5s\n",
      "[CV 2/10; 90/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 90/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 90/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 90/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.235 total time=   0.7s\n",
      "[CV 4/10; 90/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 90/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 90/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 90/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.5s\n",
      "[CV 6/10; 90/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 90/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 90/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 90/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 8/10; 90/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 90/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 90/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 90/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 90/216] START class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 90/216] END class_weight=None, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 1/10; 91/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 91/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 91/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 91/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 3/10; 91/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 91/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 4/10; 91/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 91/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 91/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 91/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 91/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 91/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 91/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 91/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 8/10; 91/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 91/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 91/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 91/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 10/10; 91/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 91/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 92/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 92/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 92/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 92/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 92/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 92/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 92/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 92/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 92/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 92/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 92/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 92/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 7/10; 92/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 92/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 92/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 92/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 92/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 92/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 92/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 92/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 93/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 93/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 93/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 93/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 93/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 93/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 93/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 93/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 93/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 93/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 93/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 93/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 93/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 93/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 93/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 93/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 93/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 93/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 93/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 93/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 94/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 94/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 94/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 94/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 94/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 94/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 94/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 94/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 94/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 94/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 94/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 94/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 94/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 94/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 94/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 94/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 94/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 94/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 94/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 94/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 95/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 95/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 95/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 95/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 95/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 95/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.118 total time=   0.5s\n",
      "[CV 4/10; 95/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 95/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 95/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 95/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 95/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 95/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 95/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 95/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 95/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 95/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 95/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 95/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 95/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 95/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 96/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 96/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 96/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 96/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 3/10; 96/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 96/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 96/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 96/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 96/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 96/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 96/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 96/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 96/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 96/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 96/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 96/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 96/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 96/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 96/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 96/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 97/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 97/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 97/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 97/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 3/10; 97/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 97/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.059 total time=   0.5s\n",
      "[CV 4/10; 97/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 97/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 97/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 97/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 97/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 97/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 97/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 97/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 97/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 97/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 97/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 97/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 97/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 97/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.5s\n",
      "[CV 1/10; 98/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 98/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 98/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 98/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 3/10; 98/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 98/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 98/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 98/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 98/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 98/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 98/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 98/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 98/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 98/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.5s\n",
      "[CV 8/10; 98/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 98/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 98/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 98/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 98/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 98/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 99/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 99/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 99/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 99/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.5s\n",
      "[CV 3/10; 99/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 99/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.059 total time=   0.5s\n",
      "[CV 4/10; 99/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 99/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 99/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 99/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.5s\n",
      "[CV 6/10; 99/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 99/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 99/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 99/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 99/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 99/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 99/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 99/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 99/216] START class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 99/216] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 100/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 100/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 100/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 100/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 100/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 100/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 100/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 100/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 100/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 100/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 100/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 100/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 100/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 100/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 100/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 100/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 100/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 100/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 100/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 100/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 101/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 101/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 101/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 101/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 101/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 101/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 101/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 101/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.235 total time=   0.6s\n",
      "[CV 5/10; 101/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 101/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 101/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 101/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 101/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 101/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 101/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 101/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 101/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 101/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 101/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 101/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 102/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 102/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 2/10; 102/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 102/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 102/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 102/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 102/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 102/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 102/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 102/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 102/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 102/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 102/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 102/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 102/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 102/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.222 total time=   0.5s\n",
      "[CV 9/10; 102/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 102/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 102/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 102/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 103/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 103/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 103/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 103/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 103/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 103/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 103/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 103/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 103/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 103/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 103/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 103/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 103/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 103/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 103/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 103/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 103/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 103/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 103/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 103/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 104/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 104/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 104/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 104/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 104/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 104/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 104/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 104/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 104/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 104/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.111 total time=   0.7s\n",
      "[CV 6/10; 104/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 104/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 104/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 104/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 104/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 104/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 104/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 104/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 104/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 104/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 1/10; 105/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 105/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 105/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 105/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 105/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 105/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 105/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 105/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 105/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 105/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.000 total time=   0.5s\n",
      "[CV 6/10; 105/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 105/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 105/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 105/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 105/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 105/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 105/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 105/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 105/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 105/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 106/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 106/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 106/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 106/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 106/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 106/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 106/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 106/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 106/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 106/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 106/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 106/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 106/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 106/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 106/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 106/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 9/10; 106/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 106/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 106/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 106/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.000 total time=   0.7s\n",
      "[CV 1/10; 107/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 107/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 2/10; 107/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 107/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 107/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 107/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 107/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 107/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 107/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 107/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.000 total time=   0.5s\n",
      "[CV 6/10; 107/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 107/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 107/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 107/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.056 total time=   0.6s\n",
      "[CV 8/10; 107/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 107/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 107/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 107/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 107/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 107/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.000 total time=   0.6s\n",
      "[CV 1/10; 108/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 108/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.056 total time=   0.6s\n",
      "[CV 2/10; 108/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 108/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.5s\n",
      "[CV 3/10; 108/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 108/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.059 total time=   0.6s\n",
      "[CV 4/10; 108/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 108/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 108/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 108/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 6/10; 108/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 108/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.111 total time=   0.6s\n",
      "[CV 7/10; 108/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 108/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 8/10; 108/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 108/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 108/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 108/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 108/216] START class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 108/216] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.000 total time=   0.6s\n",
      "[CV 1/10; 109/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 109/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 2/10; 109/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 109/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 3/10; 109/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 109/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.235 total time=   0.7s\n",
      "[CV 4/10; 109/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 109/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.059 total time=   0.6s\n",
      "[CV 5/10; 109/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 109/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 109/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 109/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 7/10; 109/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 109/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 109/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 109/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 109/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 109/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 109/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 109/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 110/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 110/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 2/10; 110/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 110/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 3/10; 110/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 110/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 110/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 110/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 110/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 110/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 110/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 110/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 7/10; 110/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 110/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 110/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 110/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 110/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 110/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 110/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 110/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.5s\n",
      "[CV 1/10; 111/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 111/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 111/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 111/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 3/10; 111/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 111/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.471 total time=   0.7s\n",
      "[CV 4/10; 111/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 111/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.588 total time=   0.7s\n",
      "[CV 5/10; 111/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 111/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 6/10; 111/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 111/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.8s\n",
      "[CV 7/10; 111/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 111/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 8/10; 111/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 111/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 111/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 111/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 111/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 111/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 1/10; 112/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 112/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 2/10; 112/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 112/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.5s\n",
      "[CV 3/10; 112/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 112/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 112/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 112/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.412 total time=   0.6s\n",
      "[CV 5/10; 112/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 112/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 6/10; 112/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 112/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 112/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 112/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 112/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 112/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 112/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 112/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 10/10; 112/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 112/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.7s\n",
      "[CV 1/10; 113/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 113/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 2/10; 113/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 113/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 3/10; 113/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 113/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.471 total time=   0.7s\n",
      "[CV 4/10; 113/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 113/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 5/10; 113/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 113/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 6/10; 113/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 113/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 113/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 113/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 113/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 113/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.7s\n",
      "[CV 9/10; 113/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 113/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 10/10; 113/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 113/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.7s\n",
      "[CV 1/10; 114/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 114/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 114/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 114/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 3/10; 114/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 114/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 114/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 114/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 114/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 114/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 6/10; 114/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 114/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.7s\n",
      "[CV 7/10; 114/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 114/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 114/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 114/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.7s\n",
      "[CV 9/10; 114/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 114/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 10/10; 114/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 114/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 115/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 115/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.5s\n",
      "[CV 2/10; 115/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 115/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.611 total time=   0.6s\n",
      "[CV 3/10; 115/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 115/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.471 total time=   0.5s\n",
      "[CV 4/10; 115/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 115/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 115/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 115/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 115/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 115/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 115/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 115/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 115/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 115/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 115/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 115/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 115/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 115/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 1/10; 116/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 116/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 116/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 116/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.611 total time=   0.6s\n",
      "[CV 3/10; 116/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 116/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 116/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 116/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 116/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 116/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 116/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 116/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.7s\n",
      "[CV 7/10; 116/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 116/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 116/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 116/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 116/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 116/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 116/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 116/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 117/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 117/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 117/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 117/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 117/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 117/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 117/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 117/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.471 total time=   0.5s\n",
      "[CV 5/10; 117/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 117/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.5s\n",
      "[CV 6/10; 117/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 117/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.7s\n",
      "[CV 7/10; 117/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 117/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 117/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 117/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 9/10; 117/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 117/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 10/10; 117/216] START class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 117/216] END class_weight=balanced, max_depth=None, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.333 total time=   0.5s\n",
      "[CV 1/10; 118/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 118/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 118/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 118/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 118/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 118/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 118/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 118/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 118/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 118/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 118/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 118/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 118/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 118/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 118/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 118/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 9/10; 118/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 118/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 118/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 118/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 119/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 119/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 2/10; 119/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 119/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 3/10; 119/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 119/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 119/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 119/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.471 total time=   0.5s\n",
      "[CV 5/10; 119/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 119/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 6/10; 119/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 119/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 119/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 119/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 8/10; 119/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 119/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 119/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 119/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 10/10; 119/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 119/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 120/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 120/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 120/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 120/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.611 total time=   0.5s\n",
      "[CV 3/10; 120/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 120/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 120/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 120/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.529 total time=   0.6s\n",
      "[CV 5/10; 120/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 120/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 120/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 120/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 120/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 120/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 8/10; 120/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 120/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 120/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 120/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 120/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 120/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.7s\n",
      "[CV 1/10; 121/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 121/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 2/10; 121/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 121/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 3/10; 121/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 121/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 121/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 121/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.412 total time=   0.6s\n",
      "[CV 5/10; 121/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 121/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 6/10; 121/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 121/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 121/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 121/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 8/10; 121/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 121/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 121/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 121/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 10/10; 121/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 121/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 1/10; 122/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 122/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 2/10; 122/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 122/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.500 total time=   0.5s\n",
      "[CV 3/10; 122/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 122/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 122/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 122/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 5/10; 122/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 122/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 6/10; 122/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 122/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 122/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 122/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 8/10; 122/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 122/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 122/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 122/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 10/10; 122/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 122/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 1/10; 123/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 123/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 123/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 123/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 123/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 123/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 123/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 123/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 123/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 123/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 123/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 123/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 123/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 123/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 123/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 123/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 123/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 123/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 10/10; 123/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 123/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 124/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 124/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 2/10; 124/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 124/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.722 total time=   0.6s\n",
      "[CV 3/10; 124/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 124/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 124/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 124/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 124/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 124/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 124/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 124/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 124/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 124/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 124/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 124/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 124/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 124/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 124/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 124/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 125/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 125/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 2/10; 125/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 125/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.722 total time=   0.6s\n",
      "[CV 3/10; 125/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 125/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 125/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 125/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 125/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 125/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 125/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 125/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 7/10; 125/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 125/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 125/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 125/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 125/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 125/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 125/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 125/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 126/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 126/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 2/10; 126/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 126/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 126/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 126/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 126/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 126/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 126/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 126/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 6/10; 126/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 126/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 126/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 126/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 126/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 126/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 126/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 126/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 10/10; 126/216] START class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 126/216] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 127/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 127/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 127/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 127/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 127/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 127/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 4/10; 127/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 127/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 127/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 127/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.056 total time=   0.6s\n",
      "[CV 6/10; 127/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 127/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 7/10; 127/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 127/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 127/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 127/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 127/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 127/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 127/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 127/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 1/10; 128/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 128/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 2/10; 128/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 128/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 3/10; 128/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 128/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.294 total time=   0.6s\n",
      "[CV 4/10; 128/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 128/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 5/10; 128/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 128/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 128/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 128/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 128/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 128/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 128/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 128/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 128/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 128/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 128/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 128/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.5s\n",
      "[CV 1/10; 129/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 129/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 2/10; 129/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 129/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.722 total time=   0.6s\n",
      "[CV 3/10; 129/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 129/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 129/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 129/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.529 total time=   0.6s\n",
      "[CV 5/10; 129/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 129/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.556 total time=   0.5s\n",
      "[CV 6/10; 129/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 129/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.5s\n",
      "[CV 7/10; 129/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 129/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 8/10; 129/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 129/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 9/10; 129/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 129/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 129/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 129/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 130/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 130/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 2/10; 130/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 130/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 3/10; 130/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 130/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 130/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 130/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.471 total time=   0.5s\n",
      "[CV 5/10; 130/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 130/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 6/10; 130/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 130/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 130/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 130/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 8/10; 130/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 130/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 130/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 130/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 130/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 130/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 1/10; 131/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 131/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 2/10; 131/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 131/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 3/10; 131/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 131/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 131/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 131/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 131/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 131/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 6/10; 131/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 131/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 131/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 131/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 8/10; 131/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 131/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 131/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 131/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 131/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 131/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 1/10; 132/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 132/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 132/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 132/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.722 total time=   0.6s\n",
      "[CV 3/10; 132/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 132/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 132/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 132/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.529 total time=   0.6s\n",
      "[CV 5/10; 132/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 132/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 132/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 132/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 132/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 132/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 8/10; 132/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 132/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 132/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 132/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 132/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 132/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 133/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 133/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.5s\n",
      "[CV 2/10; 133/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 133/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 133/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 133/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 133/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 133/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 133/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 133/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 133/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 133/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 133/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 133/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 133/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 133/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 133/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 133/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 133/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 133/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 134/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 134/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 134/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 134/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 134/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 134/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 134/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 134/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.588 total time=   0.5s\n",
      "[CV 5/10; 134/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 134/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 134/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 134/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 134/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 134/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 134/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 134/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 134/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 134/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 134/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 134/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 135/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 135/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 2/10; 135/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 135/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 135/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 135/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 135/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 135/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 135/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 135/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 135/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 135/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 135/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 135/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 135/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 135/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.5s\n",
      "[CV 9/10; 135/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 135/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 135/216] START class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 135/216] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 136/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 136/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.500 total time=   0.7s\n",
      "[CV 2/10; 136/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 136/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 3/10; 136/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 136/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 136/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 136/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.471 total time=   0.7s\n",
      "[CV 5/10; 136/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 136/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 136/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 136/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.278 total time=   0.7s\n",
      "[CV 7/10; 136/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 136/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 8/10; 136/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 136/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 136/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 136/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 136/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 136/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 1/10; 137/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 137/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 137/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 137/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 3/10; 137/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 137/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 137/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 137/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 137/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 137/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.556 total time=   0.5s\n",
      "[CV 6/10; 137/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 137/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 7/10; 137/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 137/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 8/10; 137/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 137/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 137/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 137/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 137/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 137/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 138/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 138/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 138/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 138/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 3/10; 138/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 138/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 138/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 138/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.529 total time=   0.6s\n",
      "[CV 5/10; 138/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 138/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 6/10; 138/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 138/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.7s\n",
      "[CV 7/10; 138/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 138/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.7s\n",
      "[CV 8/10; 138/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 138/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.7s\n",
      "[CV 9/10; 138/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 138/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.556 total time=   0.7s\n",
      "[CV 10/10; 138/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 138/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 139/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 139/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.7s\n",
      "[CV 2/10; 139/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 139/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.556 total time=   0.7s\n",
      "[CV 3/10; 139/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 139/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 139/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 139/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.471 total time=   0.7s\n",
      "[CV 5/10; 139/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 139/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.611 total time=   0.5s\n",
      "[CV 6/10; 139/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 139/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.7s\n",
      "[CV 7/10; 139/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 139/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 8/10; 139/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 139/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 9/10; 139/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 139/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 139/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 139/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.7s\n",
      "[CV 1/10; 140/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 140/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.7s\n",
      "[CV 2/10; 140/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 140/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.556 total time=   0.6s\n",
      "[CV 3/10; 140/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 140/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.471 total time=   0.5s\n",
      "[CV 4/10; 140/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 140/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 140/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 140/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.611 total time=   0.6s\n",
      "[CV 6/10; 140/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 140/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.7s\n",
      "[CV 7/10; 140/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 140/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.7s\n",
      "[CV 8/10; 140/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 140/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 9/10; 140/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 140/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 140/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 140/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.7s\n",
      "[CV 1/10; 141/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 141/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.7s\n",
      "[CV 2/10; 141/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 141/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 141/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 141/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.471 total time=   0.7s\n",
      "[CV 4/10; 141/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 141/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.529 total time=   0.7s\n",
      "[CV 5/10; 141/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 141/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.611 total time=   0.5s\n",
      "[CV 6/10; 141/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 141/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 141/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 141/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 141/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 141/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 9/10; 141/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 141/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.556 total time=   0.7s\n",
      "[CV 10/10; 141/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 141/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 142/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 142/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.7s\n",
      "[CV 2/10; 142/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 142/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 142/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 142/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.471 total time=   0.7s\n",
      "[CV 4/10; 142/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 142/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 142/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 142/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 142/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 142/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.7s\n",
      "[CV 7/10; 142/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 142/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.7s\n",
      "[CV 8/10; 142/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 142/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.5s\n",
      "[CV 9/10; 142/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 142/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.7s\n",
      "[CV 10/10; 142/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 142/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 143/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 143/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.7s\n",
      "[CV 2/10; 143/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 143/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.667 total time=   0.7s\n",
      "[CV 3/10; 143/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 143/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 143/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 143/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.471 total time=   0.7s\n",
      "[CV 5/10; 143/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 143/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 143/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 143/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.7s\n",
      "[CV 7/10; 143/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 143/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.5s\n",
      "[CV 8/10; 143/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 143/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.7s\n",
      "[CV 9/10; 143/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 143/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.7s\n",
      "[CV 10/10; 143/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 143/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 144/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 144/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 144/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 144/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 144/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 144/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 144/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 144/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.471 total time=   0.7s\n",
      "[CV 5/10; 144/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 144/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 144/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 144/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.7s\n",
      "[CV 7/10; 144/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 144/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.5s\n",
      "[CV 8/10; 144/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 144/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.7s\n",
      "[CV 9/10; 144/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 144/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 10/10; 144/216] START class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 144/216] END class_weight=balanced, max_depth=5, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 145/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 145/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 2/10; 145/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 145/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.556 total time=   0.5s\n",
      "[CV 3/10; 145/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 145/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 145/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 145/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.588 total time=   0.5s\n",
      "[CV 5/10; 145/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 145/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 6/10; 145/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 145/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 145/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 145/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 8/10; 145/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 145/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 9/10; 145/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 145/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 145/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 145/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 146/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 146/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.500 total time=   0.5s\n",
      "[CV 2/10; 146/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 146/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 146/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 146/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 146/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 146/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 146/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 146/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 146/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 146/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 146/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 146/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 8/10; 146/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 146/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 146/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 146/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 146/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 146/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 1/10; 147/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 147/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 147/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 147/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 147/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 147/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 147/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 147/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 147/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 147/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 6/10; 147/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 147/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 147/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 147/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 147/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 147/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 147/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 147/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 147/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 147/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 148/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 148/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 148/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 148/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 148/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 148/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 148/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 148/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 148/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 148/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 148/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 148/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 148/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 148/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 148/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 148/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.444 total time=   0.5s\n",
      "[CV 9/10; 148/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 148/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 148/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 148/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 149/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 149/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 149/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 149/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 149/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 149/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.412 total time=   0.5s\n",
      "[CV 4/10; 149/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 149/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.588 total time=   0.4s\n",
      "[CV 5/10; 149/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 149/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.556 total time=   0.5s\n",
      "[CV 6/10; 149/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 149/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 149/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 149/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 149/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 149/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 149/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 149/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 149/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 149/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 150/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 150/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 2/10; 150/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 150/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.722 total time=   0.5s\n",
      "[CV 3/10; 150/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 150/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 150/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 150/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 150/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 150/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 6/10; 150/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 150/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 150/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 150/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 150/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 150/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 150/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 150/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 150/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 150/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 151/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 151/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 151/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 151/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 151/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 151/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 151/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 151/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 151/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 151/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 151/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 151/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.5s\n",
      "[CV 7/10; 151/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 151/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 151/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 151/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 151/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 151/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.556 total time=   0.6s\n",
      "[CV 10/10; 151/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 151/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.5s\n",
      "[CV 1/10; 152/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 152/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 152/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 152/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 152/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 152/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.412 total time=   0.5s\n",
      "[CV 4/10; 152/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 152/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 152/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 152/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 152/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 152/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 152/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 152/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 152/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 152/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 152/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 152/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.556 total time=   0.6s\n",
      "[CV 10/10; 152/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 152/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 1/10; 153/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 153/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 2/10; 153/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 153/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 153/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 153/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 153/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 153/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 153/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 153/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 153/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 153/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 153/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 153/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 153/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 153/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 153/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 153/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 10/10; 153/216] START class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 153/216] END class_weight=balanced, max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 154/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 154/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 2/10; 154/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 154/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.611 total time=   0.6s\n",
      "[CV 3/10; 154/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 154/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 154/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 154/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 154/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 154/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 154/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 154/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 154/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 154/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 154/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 154/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 154/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 154/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 154/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 154/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.389 total time=   0.5s\n",
      "[CV 1/10; 155/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 155/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 2/10; 155/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 155/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 155/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 155/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.471 total time=   0.5s\n",
      "[CV 4/10; 155/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 155/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 155/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 155/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 155/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 155/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 155/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 155/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.500 total time=   0.5s\n",
      "[CV 8/10; 155/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 155/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 155/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 155/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 155/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 155/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 156/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 156/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 156/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 156/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.722 total time=   0.6s\n",
      "[CV 3/10; 156/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 156/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 156/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 156/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.588 total time=   0.5s\n",
      "[CV 5/10; 156/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 156/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 6/10; 156/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 156/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 156/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 156/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 156/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 156/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 156/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 156/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 156/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 156/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 157/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 157/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.444 total time=   0.5s\n",
      "[CV 2/10; 157/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 157/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 157/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 157/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 157/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 157/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 157/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 157/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 157/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 157/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 157/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 157/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 157/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 157/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.444 total time=   0.5s\n",
      "[CV 9/10; 157/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 157/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 157/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 157/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 158/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 158/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 2/10; 158/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 158/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 158/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 158/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 158/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 158/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 158/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 158/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.556 total time=   0.5s\n",
      "[CV 6/10; 158/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 158/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 158/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 158/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 158/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 158/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 158/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 158/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 158/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 158/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 159/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 159/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 159/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 159/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 159/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 159/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 159/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 159/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 159/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 159/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 6/10; 159/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 159/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 159/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 159/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 8/10; 159/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 159/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 9/10; 159/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 159/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 10/10; 159/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 159/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 160/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 160/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 160/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 160/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.722 total time=   0.6s\n",
      "[CV 3/10; 160/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 160/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 160/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 160/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 160/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 160/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 160/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 160/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 160/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 160/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 160/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 160/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 160/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 160/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 160/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 160/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 161/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 161/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 161/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 161/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.722 total time=   0.6s\n",
      "[CV 3/10; 161/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 161/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 161/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 161/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 161/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 161/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 161/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 161/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 161/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 161/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 161/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 161/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 161/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 161/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 161/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 161/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 162/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 162/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 162/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 162/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.722 total time=   0.6s\n",
      "[CV 3/10; 162/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 162/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 162/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 162/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 162/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 162/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 6/10; 162/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 162/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.5s\n",
      "[CV 7/10; 162/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 162/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 8/10; 162/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 162/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 162/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 162/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 162/216] START class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 162/216] END class_weight=balanced, max_depth=5, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 163/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 163/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 2/10; 163/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 163/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 3/10; 163/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 163/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.294 total time=   0.6s\n",
      "[CV 4/10; 163/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 163/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 163/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 163/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 163/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 163/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 7/10; 163/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 163/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 163/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 163/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 163/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 163/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 10/10; 163/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 163/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 164/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 164/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 2/10; 164/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 164/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 3/10; 164/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 164/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 164/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 164/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.294 total time=   0.6s\n",
      "[CV 5/10; 164/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 164/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.7s\n",
      "[CV 6/10; 164/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 164/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 164/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 164/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 164/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 164/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 164/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 164/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 164/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 164/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.5s\n",
      "[CV 1/10; 165/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 165/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 165/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 165/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.7s\n",
      "[CV 3/10; 165/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 165/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.471 total time=   0.7s\n",
      "[CV 4/10; 165/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 165/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.588 total time=   0.8s\n",
      "[CV 5/10; 165/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 165/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.611 total time=   0.7s\n",
      "[CV 6/10; 165/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 165/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.7s\n",
      "[CV 7/10; 165/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 165/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.7s\n",
      "[CV 8/10; 165/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 165/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.7s\n",
      "[CV 9/10; 165/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 165/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 165/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 165/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 1/10; 166/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 166/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.7s\n",
      "[CV 2/10; 166/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 166/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 3/10; 166/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 166/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 166/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 166/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.412 total time=   0.5s\n",
      "[CV 5/10; 166/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 166/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.5s\n",
      "[CV 6/10; 166/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 166/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.5s\n",
      "[CV 7/10; 166/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 166/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 166/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 166/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 166/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 166/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 10/10; 166/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 166/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 167/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 167/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 2/10; 167/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 167/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 3/10; 167/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 167/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 167/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 167/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 5/10; 167/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 167/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 6/10; 167/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 167/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 7/10; 167/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 167/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 8/10; 167/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 167/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 167/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 167/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 10/10; 167/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 167/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 168/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 168/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 168/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 168/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 3/10; 168/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 168/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 168/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 168/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.471 total time=   0.7s\n",
      "[CV 5/10; 168/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 168/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.611 total time=   0.5s\n",
      "[CV 6/10; 168/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 168/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.7s\n",
      "[CV 7/10; 168/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 168/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 168/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 168/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 9/10; 168/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 168/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.556 total time=   0.7s\n",
      "[CV 10/10; 168/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 168/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.5s\n",
      "[CV 1/10; 169/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 169/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 169/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 169/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.611 total time=   0.6s\n",
      "[CV 3/10; 169/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 169/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 169/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 169/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.471 total time=   0.7s\n",
      "[CV 5/10; 169/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 169/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.7s\n",
      "[CV 6/10; 169/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 169/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 169/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 169/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.5s\n",
      "[CV 8/10; 169/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 169/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 169/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 169/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 169/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 169/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 1/10; 170/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 170/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.7s\n",
      "[CV 2/10; 170/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 170/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.611 total time=   0.7s\n",
      "[CV 3/10; 170/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 170/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 170/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 170/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 170/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 170/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 170/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 170/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.7s\n",
      "[CV 7/10; 170/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 170/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 170/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 170/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 170/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 170/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 170/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 170/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 171/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 171/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 171/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 171/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 171/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 171/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 171/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 171/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.471 total time=   0.7s\n",
      "[CV 5/10; 171/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 171/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 171/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 171/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.7s\n",
      "[CV 7/10; 171/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 171/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.7s\n",
      "[CV 8/10; 171/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 171/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 171/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 171/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.7s\n",
      "[CV 10/10; 171/216] START class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 171/216] END class_weight=balanced, max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 172/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 172/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 2/10; 172/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 172/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 172/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 172/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 4/10; 172/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 172/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 172/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 172/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 172/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 172/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 172/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 172/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 172/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 172/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 9/10; 172/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 172/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 10/10; 172/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 172/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 173/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 173/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 2/10; 173/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 173/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 3/10; 173/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 173/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 173/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 173/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.353 total time=   0.5s\n",
      "[CV 5/10; 173/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 173/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 173/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 173/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 173/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 173/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 173/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 173/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 173/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 173/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 10/10; 173/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 173/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 174/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 174/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 174/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 174/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 174/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 174/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 174/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 174/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.529 total time=   0.6s\n",
      "[CV 5/10; 174/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 174/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 174/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 174/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 174/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 174/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 8/10; 174/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 174/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 174/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 174/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 174/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 174/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 175/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 175/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 2/10; 175/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 175/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 3/10; 175/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 175/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 175/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 175/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.412 total time=   0.6s\n",
      "[CV 5/10; 175/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 175/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 6/10; 175/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 175/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 175/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 175/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.7s\n",
      "[CV 8/10; 175/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 175/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 9/10; 175/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 175/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 10/10; 175/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 175/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 176/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 176/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 2/10; 176/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 176/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 3/10; 176/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 176/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 176/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 176/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 5/10; 176/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 176/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 6/10; 176/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 176/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 176/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 176/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 8/10; 176/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 176/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 176/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 176/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 10/10; 176/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 176/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 177/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 177/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 177/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 177/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 177/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 177/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 177/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 177/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 177/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 177/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 177/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 177/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 177/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 177/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 177/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 177/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 177/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 177/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 10/10; 177/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 177/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 178/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 178/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 2/10; 178/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 178/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.722 total time=   0.5s\n",
      "[CV 3/10; 178/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 178/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 178/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 178/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 178/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 178/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 178/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 178/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 178/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 178/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 178/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 178/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 178/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 178/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 178/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 178/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 179/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 179/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 2/10; 179/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 179/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.722 total time=   0.6s\n",
      "[CV 3/10; 179/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 179/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 179/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 179/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 179/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 179/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 179/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 179/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 179/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 179/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.5s\n",
      "[CV 8/10; 179/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 179/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 9/10; 179/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 179/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 179/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 179/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 180/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 180/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 2/10; 180/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 180/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 180/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 180/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 180/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 180/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 180/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 180/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 6/10; 180/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 180/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.5s\n",
      "[CV 7/10; 180/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 180/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 180/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 180/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 180/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 180/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 10/10; 180/216] START class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 180/216] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 181/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 181/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 181/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 181/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 3/10; 181/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 181/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.5s\n",
      "[CV 4/10; 181/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 181/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 181/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 181/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 181/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 181/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 7/10; 181/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 181/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 8/10; 181/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 181/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 181/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 181/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 10/10; 181/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 181/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 182/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 182/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 2/10; 182/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 182/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 3/10; 182/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 182/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 182/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 182/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 5/10; 182/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 182/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 6/10; 182/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 182/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.5s\n",
      "[CV 7/10; 182/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 182/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 182/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 182/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 182/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 182/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 10/10; 182/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 182/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 1/10; 183/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 183/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 2/10; 183/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 183/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.722 total time=   0.6s\n",
      "[CV 3/10; 183/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 183/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.412 total time=   0.5s\n",
      "[CV 4/10; 183/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 183/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 183/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 183/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 183/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 183/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 183/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 183/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 8/10; 183/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 183/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 9/10; 183/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 183/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 183/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 183/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 184/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 184/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 2/10; 184/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 184/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 3/10; 184/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 184/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 184/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 184/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.529 total time=   0.6s\n",
      "[CV 5/10; 184/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 184/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 6/10; 184/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 184/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 184/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 184/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 8/10; 184/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 184/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 184/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 184/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 10/10; 184/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 184/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 1/10; 185/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 185/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 2/10; 185/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 185/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 3/10; 185/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 185/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 185/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 185/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.529 total time=   0.6s\n",
      "[CV 5/10; 185/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 185/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 6/10; 185/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 185/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 185/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 185/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 8/10; 185/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 185/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 9/10; 185/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 185/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 10/10; 185/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 185/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 1/10; 186/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 186/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 186/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 186/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 186/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 186/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 186/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 186/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 186/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 186/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 186/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 186/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 186/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 186/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 8/10; 186/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 186/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 186/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 186/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 186/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 186/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 187/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 187/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 187/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 187/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 187/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 187/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 187/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 187/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 187/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 187/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 187/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 187/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 187/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 187/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 187/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 187/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 187/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 187/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 187/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 187/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 188/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 188/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 188/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 188/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 188/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 188/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 188/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 188/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 188/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 188/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 188/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 188/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 188/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 188/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.5s\n",
      "[CV 8/10; 188/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 188/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 188/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 188/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 10/10; 188/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 188/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 189/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 189/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 2/10; 189/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 189/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 189/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 189/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 189/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 189/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 189/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 189/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 189/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 189/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 189/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 189/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 189/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 189/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 189/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 189/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 10/10; 189/216] START class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 189/216] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 190/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 190/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 2/10; 190/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 190/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.7s\n",
      "[CV 3/10; 190/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 190/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.235 total time=   0.6s\n",
      "[CV 4/10; 190/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 190/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.059 total time=   0.7s\n",
      "[CV 5/10; 190/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 190/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 6/10; 190/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 190/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 190/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 190/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 190/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 190/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.7s\n",
      "[CV 9/10; 190/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 190/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 190/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 190/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 191/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 191/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 2/10; 191/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 191/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 3/10; 191/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 191/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 191/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 191/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.176 total time=   0.6s\n",
      "[CV 5/10; 191/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 191/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 191/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 191/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 191/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 191/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 191/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 191/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 191/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 191/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 10/10; 191/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 191/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=10;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 192/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 192/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.7s\n",
      "[CV 2/10; 192/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 192/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 3/10; 192/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 192/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.471 total time=   0.5s\n",
      "[CV 4/10; 192/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 192/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 192/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 192/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.611 total time=   0.7s\n",
      "[CV 6/10; 192/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 192/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 192/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 192/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 8/10; 192/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 192/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 192/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 192/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.7s\n",
      "[CV 10/10; 192/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 192/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=30;, score=0.278 total time=   0.6s\n",
      "[CV 1/10; 193/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 193/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 2/10; 193/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 193/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.7s\n",
      "[CV 3/10; 193/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 193/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.471 total time=   0.7s\n",
      "[CV 4/10; 193/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 193/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.412 total time=   0.6s\n",
      "[CV 5/10; 193/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 193/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 6/10; 193/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 193/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.7s\n",
      "[CV 7/10; 193/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 193/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 193/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 193/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.7s\n",
      "[CV 9/10; 193/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 193/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 10/10; 193/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 193/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 1/10; 194/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 194/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 2/10; 194/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 194/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 3/10; 194/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 194/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 194/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 194/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.412 total time=   0.6s\n",
      "[CV 5/10; 194/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 194/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 6/10; 194/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 194/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.7s\n",
      "[CV 7/10; 194/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 194/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 8/10; 194/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 194/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 9/10; 194/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 194/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 10/10; 194/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 194/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 1/10; 195/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 195/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 2/10; 195/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 195/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.611 total time=   0.5s\n",
      "[CV 3/10; 195/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 195/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 195/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 195/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.471 total time=   0.7s\n",
      "[CV 5/10; 195/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 195/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 6/10; 195/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 195/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.7s\n",
      "[CV 7/10; 195/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 195/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.7s\n",
      "[CV 8/10; 195/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 195/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 9/10; 195/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 195/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 10/10; 195/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 195/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 196/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 196/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 196/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 196/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.611 total time=   0.6s\n",
      "[CV 3/10; 196/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 196/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.471 total time=   0.8s\n",
      "[CV 4/10; 196/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 196/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 196/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 196/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.7s\n",
      "[CV 6/10; 196/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 196/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 196/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 196/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 196/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 196/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.7s\n",
      "[CV 9/10; 196/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 196/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 196/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 196/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 197/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 197/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 197/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 197/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.611 total time=   0.6s\n",
      "[CV 3/10; 197/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 197/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.471 total time=   0.5s\n",
      "[CV 4/10; 197/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 197/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 197/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 197/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.7s\n",
      "[CV 6/10; 197/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 197/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 7/10; 197/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 197/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 197/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 197/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 9/10; 197/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 197/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 10/10; 197/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 197/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 198/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 198/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.7s\n",
      "[CV 2/10; 198/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 198/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 198/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 198/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 4/10; 198/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 198/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 198/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 198/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 198/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 198/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 198/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 198/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 8/10; 198/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 198/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.6s\n",
      "[CV 9/10; 198/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 198/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.5s\n",
      "[CV 10/10; 198/216] START class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 198/216] END class_weight=balanced, max_depth=20, max_features=None, min_samples_leaf=10, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 1/10; 199/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 199/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 2/10; 199/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 199/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 199/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 199/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 4/10; 199/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 199/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.118 total time=   0.6s\n",
      "[CV 5/10; 199/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 199/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 6/10; 199/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 199/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 7/10; 199/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 199/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 8/10; 199/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 199/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.4s\n",
      "[CV 9/10; 199/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 199/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 199/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 199/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 1/10; 200/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 200/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 2/10; 200/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 200/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 3/10; 200/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 200/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.353 total time=   0.6s\n",
      "[CV 4/10; 200/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 200/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.471 total time=   0.6s\n",
      "[CV 5/10; 200/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 200/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 6/10; 200/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 200/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.6s\n",
      "[CV 7/10; 200/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 200/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 8/10; 200/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 200/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 9/10; 200/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 200/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.6s\n",
      "[CV 10/10; 200/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 200/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.6s\n",
      "[CV 1/10; 201/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 201/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.6s\n",
      "[CV 2/10; 201/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 201/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.611 total time=   0.6s\n",
      "[CV 3/10; 201/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 201/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.412 total time=   0.5s\n",
      "[CV 4/10; 201/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 201/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.529 total time=   0.6s\n",
      "[CV 5/10; 201/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 201/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.556 total time=   0.6s\n",
      "[CV 6/10; 201/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 201/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.6s\n",
      "[CV 7/10; 201/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 201/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 8/10; 201/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 201/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.7s\n",
      "[CV 9/10; 201/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 201/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 201/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 201/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 202/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 202/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.7s\n",
      "[CV 2/10; 202/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 202/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.500 total time=   0.5s\n",
      "[CV 3/10; 202/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 202/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.353 total time=   0.5s\n",
      "[CV 4/10; 202/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 202/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.412 total time=   0.5s\n",
      "[CV 5/10; 202/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 202/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 6/10; 202/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 202/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.5s\n",
      "[CV 7/10; 202/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 202/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.5s\n",
      "[CV 8/10; 202/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 202/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 9/10; 202/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 202/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 10/10; 202/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 202/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.6s\n",
      "[CV 1/10; 203/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 203/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 2/10; 203/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 203/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.500 total time=   0.5s\n",
      "[CV 3/10; 203/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 203/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.353 total time=   0.5s\n",
      "[CV 4/10; 203/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 203/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.412 total time=   0.5s\n",
      "[CV 5/10; 203/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 203/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 6/10; 203/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 203/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 7/10; 203/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 203/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 8/10; 203/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 203/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 9/10; 203/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 203/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 10/10; 203/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 203/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.6s\n",
      "[CV 1/10; 204/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 204/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 2/10; 204/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 204/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.667 total time=   0.5s\n",
      "[CV 3/10; 204/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 204/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.471 total time=   0.5s\n",
      "[CV 4/10; 204/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 204/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 204/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 204/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 6/10; 204/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 204/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.5s\n",
      "[CV 7/10; 204/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 204/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 8/10; 204/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 204/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 204/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 204/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.556 total time=   0.5s\n",
      "[CV 10/10; 204/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 204/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 205/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 205/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 2/10; 205/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 205/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.722 total time=   0.5s\n",
      "[CV 3/10; 205/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 205/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.412 total time=   0.5s\n",
      "[CV 4/10; 205/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 205/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.588 total time=   0.5s\n",
      "[CV 5/10; 205/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 205/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.5s\n",
      "[CV 6/10; 205/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 205/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 7/10; 205/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 205/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 205/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 205/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 9/10; 205/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 205/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 205/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 205/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.5s\n",
      "[CV 1/10; 206/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 206/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 2/10; 206/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 206/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.722 total time=   0.5s\n",
      "[CV 3/10; 206/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 206/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.412 total time=   0.5s\n",
      "[CV 4/10; 206/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 206/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.588 total time=   0.5s\n",
      "[CV 5/10; 206/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 206/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.6s\n",
      "[CV 6/10; 206/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 206/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 7/10; 206/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 206/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.6s\n",
      "[CV 8/10; 206/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 206/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 9/10; 206/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 206/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 206/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 206/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.6s\n",
      "[CV 1/10; 207/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 207/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 2/10; 207/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 207/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.667 total time=   0.5s\n",
      "[CV 3/10; 207/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 207/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.412 total time=   0.5s\n",
      "[CV 4/10; 207/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 207/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.588 total time=   0.5s\n",
      "[CV 5/10; 207/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 207/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.611 total time=   0.5s\n",
      "[CV 6/10; 207/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 207/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.5s\n",
      "[CV 7/10; 207/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 207/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 8/10; 207/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 207/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.5s\n",
      "[CV 9/10; 207/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 207/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.5s\n",
      "[CV 10/10; 207/216] START class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 207/216] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.5s\n",
      "[CV 1/10; 208/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 1/10; 208/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 2/10; 208/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 2/10; 208/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.6s\n",
      "[CV 3/10; 208/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 3/10; 208/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.176 total time=   0.5s\n",
      "[CV 4/10; 208/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 4/10; 208/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.118 total time=   0.5s\n",
      "[CV 5/10; 208/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 5/10; 208/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.056 total time=   0.5s\n",
      "[CV 6/10; 208/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 6/10; 208/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 7/10; 208/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 7/10; 208/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.111 total time=   0.5s\n",
      "[CV 8/10; 208/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 8/10; 208/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 9/10; 208/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 9/10; 208/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.6s\n",
      "[CV 10/10; 208/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2\n",
      "[CV 10/10; 208/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2;, score=0.167 total time=   0.5s\n",
      "[CV 1/10; 209/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 1/10; 209/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 2/10; 209/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 2/10; 209/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 3/10; 209/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 3/10; 209/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.294 total time=   0.6s\n",
      "[CV 4/10; 209/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 4/10; 209/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.353 total time=   0.5s\n",
      "[CV 5/10; 209/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 5/10; 209/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 6/10; 209/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 6/10; 209/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 7/10; 209/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 7/10; 209/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 8/10; 209/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 8/10; 209/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.5s\n",
      "[CV 9/10; 209/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 9/10; 209/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.278 total time=   0.5s\n",
      "[CV 10/10; 209/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10\n",
      "[CV 10/10; 209/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10;, score=0.167 total time=   0.5s\n",
      "[CV 1/10; 210/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 1/10; 210/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.556 total time=   0.5s\n",
      "[CV 2/10; 210/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 2/10; 210/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.722 total time=   0.5s\n",
      "[CV 3/10; 210/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 3/10; 210/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.412 total time=   0.5s\n",
      "[CV 4/10; 210/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 4/10; 210/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.529 total time=   0.6s\n",
      "[CV 5/10; 210/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 5/10; 210/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.556 total time=   0.5s\n",
      "[CV 6/10; 210/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 6/10; 210/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.5s\n",
      "[CV 7/10; 210/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 7/10; 210/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.4s\n",
      "[CV 8/10; 210/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 8/10; 210/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 9/10; 210/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 9/10; 210/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 210/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30\n",
      "[CV 10/10; 210/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=30;, score=0.333 total time=   0.5s\n",
      "[CV 1/10; 211/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 1/10; 211/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.6s\n",
      "[CV 2/10; 211/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 2/10; 211/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.444 total time=   0.6s\n",
      "[CV 3/10; 211/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 3/10; 211/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.353 total time=   0.5s\n",
      "[CV 4/10; 211/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 4/10; 211/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.471 total time=   0.5s\n",
      "[CV 5/10; 211/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 5/10; 211/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.389 total time=   0.5s\n",
      "[CV 6/10; 211/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 6/10; 211/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.278 total time=   0.5s\n",
      "[CV 7/10; 211/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 7/10; 211/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 8/10; 211/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 8/10; 211/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 9/10; 211/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 9/10; 211/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 211/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2\n",
      "[CV 10/10; 211/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=2;, score=0.222 total time=   0.6s\n",
      "[CV 1/10; 212/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 1/10; 212/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 2/10; 212/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 2/10; 212/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.444 total time=   0.5s\n",
      "[CV 3/10; 212/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 3/10; 212/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.353 total time=   0.5s\n",
      "[CV 4/10; 212/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 4/10; 212/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.471 total time=   0.5s\n",
      "[CV 5/10; 212/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 5/10; 212/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 6/10; 212/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 6/10; 212/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.278 total time=   0.5s\n",
      "[CV 7/10; 212/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 7/10; 212/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 8/10; 212/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 8/10; 212/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 9/10; 212/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 9/10; 212/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 212/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10\n",
      "[CV 10/10; 212/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=10;, score=0.222 total time=   0.5s\n",
      "[CV 1/10; 213/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 1/10; 213/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 2/10; 213/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 2/10; 213/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.722 total time=   0.5s\n",
      "[CV 3/10; 213/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 3/10; 213/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 213/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 4/10; 213/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.529 total time=   0.5s\n",
      "[CV 5/10; 213/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 5/10; 213/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.556 total time=   0.5s\n",
      "[CV 6/10; 213/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 6/10; 213/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 213/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 7/10; 213/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 8/10; 213/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 8/10; 213/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 9/10; 213/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 9/10; 213/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 213/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30\n",
      "[CV 10/10; 213/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=5, min_samples_split=30;, score=0.389 total time=   0.5s\n",
      "[CV 1/10; 214/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 1/10; 214/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.5s\n",
      "[CV 2/10; 214/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 2/10; 214/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.667 total time=   0.5s\n",
      "[CV 3/10; 214/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 3/10; 214/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.412 total time=   0.5s\n",
      "[CV 4/10; 214/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 4/10; 214/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.588 total time=   0.6s\n",
      "[CV 5/10; 214/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 5/10; 214/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.556 total time=   0.5s\n",
      "[CV 6/10; 214/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 6/10; 214/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 7/10; 214/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 7/10; 214/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.500 total time=   0.5s\n",
      "[CV 8/10; 214/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 8/10; 214/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.389 total time=   0.5s\n",
      "[CV 9/10; 214/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 9/10; 214/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 214/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2\n",
      "[CV 10/10; 214/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=2;, score=0.333 total time=   0.5s\n",
      "[CV 1/10; 215/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 1/10; 215/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.5s\n",
      "[CV 2/10; 215/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 2/10; 215/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.667 total time=   0.5s\n",
      "[CV 3/10; 215/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 3/10; 215/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.412 total time=   0.5s\n",
      "[CV 4/10; 215/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 4/10; 215/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.588 total time=   0.5s\n",
      "[CV 5/10; 215/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 5/10; 215/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.556 total time=   0.5s\n",
      "[CV 6/10; 215/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 6/10; 215/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 7/10; 215/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 7/10; 215/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.500 total time=   0.5s\n",
      "[CV 8/10; 215/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 8/10; 215/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.389 total time=   0.5s\n",
      "[CV 9/10; 215/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 9/10; 215/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.444 total time=   0.5s\n",
      "[CV 10/10; 215/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10\n",
      "[CV 10/10; 215/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=10;, score=0.333 total time=   0.5s\n",
      "[CV 1/10; 216/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 1/10; 216/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.444 total time=   0.5s\n",
      "[CV 2/10; 216/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 2/10; 216/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.667 total time=   0.6s\n",
      "[CV 3/10; 216/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 3/10; 216/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.412 total time=   0.6s\n",
      "[CV 4/10; 216/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 4/10; 216/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.588 total time=   0.5s\n",
      "[CV 5/10; 216/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 5/10; 216/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.556 total time=   0.5s\n",
      "[CV 6/10; 216/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 6/10; 216/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.6s\n",
      "[CV 7/10; 216/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 7/10; 216/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 8/10; 216/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 8/10; 216/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.5s\n",
      "[CV 9/10; 216/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 9/10; 216/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.500 total time=   0.5s\n",
      "[CV 10/10; 216/216] START class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30\n",
      "[CV 10/10; 216/216] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=10, min_samples_split=30;, score=0.389 total time=   0.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-19.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-19.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-19 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-19 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-19 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-19 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-19 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-19 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-19 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-19 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(n_estimators=200, n_jobs=4,\n",
       "                                              random_state=67),\n",
       "             param_grid={&#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 5, 10, 20],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 10, 30]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">RandomForestC...ndom_state=67)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;], &#x27;max_depth&#x27;: [None, 5, ...], &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, ...], &#x27;min_samples_leaf&#x27;: [1, 5, ...], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;recall&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">StratifiedKFo... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=5, min_samples_leaf=5,\n",
       "                       min_samples_split=30, n_estimators=200, n_jobs=4,\n",
       "                       random_state=67)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.<br>Note: This parameter is tree-specific.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">30</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D%22sqrt%22\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.accuracy_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">67</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=class_weight,-%7B%22balanced%22%2C%20%22balanced_subsample%22%7D%2C%20dict%20or%20list%20of%20dicts%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>The \"balanced_subsample\" mode is the same as \"balanced\" except that<br>weights are computed based on the bootstrap sample for every tree<br>grown.<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-19');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(n_estimators=200, n_jobs=4,\n",
       "                                              random_state=67),\n",
       "             param_grid={'class_weight': [None, 'balanced'],\n",
       "                         'max_depth': [None, 5, 10, 20],\n",
       "                         'max_features': [None, 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 5, 10],\n",
       "                         'min_samples_split': [2, 10, 30]},\n",
       "             scoring='recall', verbose=10)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_RF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e49f5e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall coreespong to random forest using this combination is 0.5111111111111112\n"
     ]
    }
   ],
   "source": [
    "print( f'The recall coreespong to random forest using this combination is {gridsearch_RF.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5ec5c104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recall, auc and mse  of best log_reg combination is is equal to [0.4406779661016949, 0.771323569743843, 0.1875] \n"
     ]
    }
   ],
   "source": [
    "best_RF = gridsearch_RF.best_estimator_\n",
    "\n",
    "y_precicted_rf = best_RF.predict(X_test)\n",
    "y_proba_RF = best_RF.predict_proba(X_test)[:,1]\n",
    "\n",
    "recall_RF = recall_score(y_test,y_precicted_rf)\n",
    "roc_auc_RF = roc_auc_score( y_test, y_proba_RF)\n",
    "mse_RF = mean_squared_error(y_test, y_precicted_rf)\n",
    "\n",
    "print(f'The recall, auc and mse  of best log_reg combination is is equal to {[recall_RF, roc_auc_RF, mse_RF]} ')\n",
    "\n",
    "best_performances.loc['random forest'] = (recall_RF, roc_auc_RF, mse_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1d70168a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifictaion report looks like \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       309\n",
      "           1       0.42      0.44      0.43        59\n",
      "\n",
      "    accuracy                           0.81       368\n",
      "   macro avg       0.66      0.66      0.66       368\n",
      "weighted avg       0.82      0.81      0.81       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('The classifictaion report looks like \\n', classification_report(y_test,y_precicted_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "de4b403c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_rf = pd.DataFrame(confusion_matrix(y_test, y_precicted_rf))\n",
    "\n",
    "sns.heatmap(confusion_matrix_rf , annot= True , cmap='YlGnBu', fmt ='g')\n",
    "plt.title('Confusion matrix of Random Forest best model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bb3ecb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For random forest the best combination of params is {'class_weight': 'balanced', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 30} \n"
     ]
    }
   ],
   "source": [
    "print( f'For random forest the best combination of params is {gridsearch_RF.best_params_} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fe308",
   "metadata": {},
   "source": [
    "### Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2631090",
   "metadata": {},
   "source": [
    "The gridsearch did actually help us boost our metrics, we went from a recall = 0.17 using just the default values on every parameter to a recall of 0.51 on the validation on  average \n",
    "\n",
    "Tested on a dataset never seen before , we got a Recall = 0.44 , an AUC = 0.77 and an MSE = 0.18\n",
    "\n",
    "For auc and recall , both of them were lower than the best estimator of logistic regression , approxiamtly the same auc but a huge difference when it comes to recall.\n",
    "\n",
    "On the other hand , we got ourselves a slightly lower mse on the test set.\n",
    "\n",
    "the first two lines of the report shows the classical metrics depending on wether we're trying to predict the class 0 and 1.\n",
    "\n",
    "We can see a huge difference between the performance when we're trying to predict class 0 (Non churn ) VS class 1 ( churn ), this difference was expected since dataset is imbalance and current employees are dominant ( 84% ). but the difference is still high \n",
    "\n",
    "Although the best estimator has 'balanced' in the parameter class_weight that takes into consideration the ombalance and adjusts the splitting by taking into consideration the different proportion of the two classes.\n",
    "\n",
    "Still, in the confusion matrix , we cans see that among the class 1 ( employees that left ) : 26 were correctly predicted but 33 were not ( False negatives ), which when it comes to employees who churn, we make more mistakes that predicting that they will stay than actually finding out they're leaving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed04f239",
   "metadata": {},
   "source": [
    "### Threshold Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be020748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#we already have a list of thresholds from the study on logistic regression\n",
    "\n",
    "recalls_rf, precisions_rf = [], []\n",
    "for threshold_ in thresholds :\n",
    "    y_updated = (y_proba_RF >= threshold_).astype(int)\n",
    "    recalls_rf.append(recall_score(y_test, y_updated))\n",
    "    precisions_rf.append(precision_score(y_test,y_updated))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(thresholds, recalls_rf, label = 'Recall' )\n",
    "plt.plot(thresholds,precisions_rf, label ='Precision')\n",
    "plt.xlabel('Thresholds')\n",
    "plt.ylabel('Metric')\n",
    "plt.title('Recall and precision tradeoff for random forest best model ')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ab325",
   "metadata": {},
   "source": [
    "Same on what was said before, we can clearly see the trade off between the two of the metrics depending on the threshold ( the bigger the threshold , the more we are insisting and prudent on deciding if a person is churning , --> less people decided as churned  unitil we decide no one is churninng --> this will cause a recall of 0 because we miss all the churing ones but a high precision because no false positives)\n",
    "\n",
    "A decision of the threshold is strongly depending on the cost of each error , until then we'll keep a threshold of 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb3071e",
   "metadata": {},
   "source": [
    "### Feature importance \n",
    "\n",
    "For a feature j:\n",
    "\n",
    "Importance = total reduction in impurity (Gini or entropy) caused by splits using feature j, averaged over all trees.\n",
    "\n",
    "    High importance → feature is frequently used and reduces uncertainty\n",
    "\n",
    "    Low importance → feature rarely helps splitting\n",
    "\n",
    "Importance is relative, not absolute\n",
    "\n",
    "    No direction (no “positive” or “negative” effect)\n",
    "\n",
    "You cannot say how the feature affects attrition, only that it matters.\n",
    "\n",
    "Important limitations (must know)\n",
    "\n",
    "Biased toward:\n",
    "\n",
    "    continuous variables\n",
    "\n",
    "    high-cardinality features\n",
    "\n",
    "    Correlated features split importance\n",
    "\n",
    "-->Not causal / Not comparable to LR coefficients\n",
    "\n",
    ":)  Better alternative (recommended) : Permutation importance !!!!!!!!!!!!\n",
    "\n",
    "    Measure performance drop when a feature is randomly shuffled.\n",
    "\n",
    "This answers: “How much does the model rely on this feature?” Much more reliable for interpretation.\n",
    "\n",
    "For one feature Xj:\n",
    "\n",
    "Measure baseline performance (e.g. recall) on a validation set\n",
    "\n",
    "Randomly shuffle values of Xj across samples\n",
    "    \n",
    "    → destroys its information\n",
    "\n",
    "Measure performance again\n",
    "\n",
    "    Performance drop = importance of xj\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4fc02522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverTime                0.098565\n",
       "TotalWorkingYears       0.096400\n",
       "Age                     0.092090\n",
       "MonthlyIncome           0.089755\n",
       "YearsWithCurrManager    0.077709\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = best_RF.feature_importances_\n",
    "\n",
    "features_RF = pd.Series(importances, index = X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "features_RF.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbab0bd",
   "metadata": {},
   "source": [
    "As mentioned before , the results are not signed, so we don't now if each feature is helping us to decide if the feature is responsible for an employee churning or staying.\n",
    "\n",
    "however in term of deciding how they contribute so minimizing the impurity during splits and separating samples ( churn vs staying), the three that comes first are :\n",
    "\n",
    "    Overtime\n",
    "\n",
    "    Total Working Years\n",
    "\n",
    "    Age\n",
    "\n",
    "I suspect that we would have gotten better result if we did not adjust the numerical variables ( scalling + fixing the skewness), but we'll deal with that later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27261620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "features_RF.head(15).plot(kind=\"barh\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba261a",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "on the comparaison earlier between the different models we saw that svm as a classifier has some really promising results specially for linear kernel\n",
    "\n",
    "for this, we decided to explore this model as well and see if we can can push it to surpass linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "51180aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value for fit_time on validation is 0.07581758499145508\n",
      "The mean value for score_time on validation is 0.014889287948608398\n",
      "The mean value for test_roc_auc on validation is 0.846675650157211\n",
      "The mean value for test_recall on validation is 0.7522875816993464\n",
      "The mean value for test_precision on validation is 0.43406034863974235\n",
      "The mean value for test_f1 on validation is 0.547904934808301\n"
     ]
    }
   ],
   "source": [
    "Kfold_svm = StratifiedKFold(n_splits=10, shuffle= True, random_state=42)\n",
    "\n",
    "model_SVM = SVC(kernel='linear' , class_weight='balanced')\n",
    "\n",
    "crossV_SVC = cross_validate(\n",
    "    estimator=model_SVM,\n",
    "    X=X_train, y =y_train,\n",
    "    cv= Kfold_svm,\n",
    "    scoring= ['roc_auc', 'recall', 'precision', 'f1']\n",
    "                            )\n",
    "\n",
    "for key, value in crossV_SVC.items():\n",
    "    print(f'The mean value for {key} on validation is {value.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39db3f",
   "metadata": {},
   "source": [
    "From what we can see above , the recall is pretty satisfying before any parameter tuning. \n",
    "\n",
    "We know that regarding the kernel the score of the metrics reach their max when its 'linear', however for the benefit of the doubt we'll try other ones when doing some hyperparameter tuning \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "81868b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-30.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-30.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-30 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-30 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-30 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-30 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-30 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-30 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-30 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-30 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-30 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-30 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-30 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-30 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-30 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=SVC(random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: array([ 0.1       ,  2.31111111,  4.52222222,  6.73333333,  8.94444444,\n",
       "       11.15555556, 13.36666667, 15.57777778, 17.78888889, 20.        ]),\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;degree&#x27;: [2, 3, 4, 5], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">SVC(random_state=42)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;C&#x27;: array([ 0.1  ... 20.        ]), &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;], &#x27;degree&#x27;: [2, 3, ...], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;recall&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">StratifiedKFo... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>estimator: SVC</div></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"estimator__\"><pre>SVC(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></div></label><div class=\"sk-toggleable__content \" data-param-prefix=\"estimator__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Regularization parameter. The strength of the regularization is<br>inversely proportional to C. Must be strictly positive. The penalty<br>is a squared l2 penalty. For an intuitive visualization of the effects<br>of scaling the regularization parameter C, see<br>:ref:`sphx_glr_auto_examples_svm_plot_svm_scale_c.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('kernel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=kernel,-%7B%27linear%27%2C%20%27poly%27%2C%20%27rbf%27%2C%20%27sigmoid%27%2C%20%27precomputed%27%7D%20or%20callable%2C%20%20%20%20%20%20%20%20%20%20default%3D%27rbf%27\">\n",
       "            kernel\n",
       "            <span class=\"param-doc-description\">kernel: {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable,          default='rbf'<br><br>Specifies the kernel type to be used in the algorithm. If<br>none is given, 'rbf' will be used. If a callable is given it is used to<br>pre-compute the kernel matrix from data matrices; that matrix should be<br>an array of shape ``(n_samples, n_samples)``. For an intuitive<br>visualization of different kernel types see<br>:ref:`sphx_glr_auto_examples_svm_plot_svm_kernels.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;rbf&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('degree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=degree,-int%2C%20default%3D3\">\n",
       "            degree\n",
       "            <span class=\"param-doc-description\">degree: int, default=3<br><br>Degree of the polynomial kernel function ('poly').<br>Must be non-negative. Ignored by all other kernels.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=gamma,-%7B%27scale%27%2C%20%27auto%27%7D%20or%20float%2C%20default%3D%27scale%27\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: {'scale', 'auto'} or float, default='scale'<br><br>Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.<br><br>- if ``gamma='scale'`` (default) is passed then it uses<br>  1 / (n_features * X.var()) as value of gamma,<br>- if 'auto', uses 1 / n_features<br>- if float, must be non-negative.<br><br>.. versionchanged:: 0.22<br>   The default value of ``gamma`` changed from 'auto' to 'scale'.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;scale&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('coef0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=coef0,-float%2C%20default%3D0.0\">\n",
       "            coef0\n",
       "            <span class=\"param-doc-description\">coef0: float, default=0.0<br><br>Independent term in kernel function.<br>It is only significant in 'poly' and 'sigmoid'.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shrinking',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=shrinking,-bool%2C%20default%3DTrue\">\n",
       "            shrinking\n",
       "            <span class=\"param-doc-description\">shrinking: bool, default=True<br><br>Whether to use the shrinking heuristic.<br>See the :ref:`User Guide <shrinking_svm>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('probability',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=probability,-bool%2C%20default%3DFalse\">\n",
       "            probability\n",
       "            <span class=\"param-doc-description\">probability: bool, default=False<br><br>Whether to enable probability estimates. This must be enabled prior<br>to calling `fit`, will slow down that method as it internally uses<br>5-fold cross-validation, and `predict_proba` may be inconsistent with<br>`predict`. Read more in the :ref:`User Guide <scores_probabilities>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=tol,-float%2C%20default%3D1e-3\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-3<br><br>Tolerance for stopping criterion.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cache_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=cache_size,-float%2C%20default%3D200\">\n",
       "            cache_size\n",
       "            <span class=\"param-doc-description\">cache_size: float, default=200<br><br>Specify the size of the kernel cache (in MB).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Set the parameter C of class i to class_weight[i]*C for<br>SVC. If not given, all classes are supposed to have<br>weight one.<br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>Enable verbose output. Note that this setting takes advantage of a<br>per-process runtime setting in libsvm that, if enabled, may not work<br>properly in a multithreaded context.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=max_iter,-int%2C%20default%3D-1\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=-1<br><br>Hard limit on iterations within solver, or -1 for no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decision_function_shape',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=decision_function_shape,-%7B%27ovo%27%2C%20%27ovr%27%7D%2C%20default%3D%27ovr%27\">\n",
       "            decision_function_shape\n",
       "            <span class=\"param-doc-description\">decision_function_shape: {'ovo', 'ovr'}, default='ovr'<br><br>Whether to return a one-vs-rest ('ovr') decision function of shape<br>(n_samples, n_classes) as all other classifiers, or the original<br>one-vs-one ('ovo') decision function of libsvm which has shape<br>(n_samples, n_classes * (n_classes - 1) / 2). However, note that<br>internally, one-vs-one ('ovo') is always used as a multi-class strategy<br>to train models; an ovr matrix is only constructed from the ovo matrix.<br>The parameter is ignored for binary classification.<br><br>.. versionchanged:: 0.19<br>    decision_function_shape is 'ovr' by default.<br><br>.. versionadded:: 0.17<br>   *decision_function_shape='ovr'* is recommended.<br><br>.. versionchanged:: 0.17<br>   Deprecated *decision_function_shape='ovo' and None*.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;ovr&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('break_ties',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=break_ties,-bool%2C%20default%3DFalse\">\n",
       "            break_ties\n",
       "            <span class=\"param-doc-description\">break_ties: bool, default=False<br><br>If true, ``decision_function_shape='ovr'``, and number of classes > 2,<br>:term:`predict` will break ties according to the confidence values of<br>:term:`decision_function`; otherwise the first class among the tied<br>classes is returned. Please note that breaking ties comes at a<br>relatively high computational cost compared to a simple predict. See<br>:ref:`sphx_glr_auto_examples_svm_plot_svm_tie_breaking.py` for an<br>example of its usage with ``decision_function_shape='ovr'``.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the pseudo random number generation for shuffling the data for<br>probability estimates. Ignored when `probability` is False.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-30');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=SVC(random_state=42),\n",
       "             param_grid={'C': array([ 0.1       ,  2.31111111,  4.52222222,  6.73333333,  8.94444444,\n",
       "       11.15555556, 13.36666667, 15.57777778, 17.78888889, 20.        ]),\n",
       "                         'class_weight': [None, 'balanced'],\n",
       "                         'degree': [2, 3, 4, 5], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the kfold is already declared\n",
    "\n",
    "parametersgrid_SVC = {\n",
    "    'kernel' : ['linear', 'rbf','poly'],\n",
    "    'C': np.linspace(0.1, 20,10) , #     A higher C value makes the model aim for fewer misclassifications by using a smaller margin, while a lower C allows more misclassifications with a wider margin.\n",
    "    'class_weight': [None , 'balanced'],\n",
    "    'gamma': ['scale', 'auto'], # valable only for poly and rbf\n",
    "    'degree' : [2,3,4,5]\n",
    "}\n",
    "\n",
    "grid_search_svc = GridSearchCV(\n",
    "    estimator= SVC(random_state=42),\n",
    "    param_grid= parametersgrid_SVC,\n",
    "    scoring = 'recall',\n",
    "    verbose = 2,\n",
    "    cv = Kfold_svm\n",
    ")\n",
    "\n",
    "grid_search_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1adfd93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=0.1, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=2.311111111111111, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=4.522222222222221, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=6.7333333333333325, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=8.944444444444443, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=11.155555555555553, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   1.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   1.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   1.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   1.2s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   1.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   1.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   1.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   1.1s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=13.366666666666665, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=15.577777777777776, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.4s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   1.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   1.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   1.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   1.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=17.788888888888888, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.5s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=None, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   1.4s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   1.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   1.4s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   1.4s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   1.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   1.4s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   1.4s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   1.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   1.4s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   1.4s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   1.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   1.4s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.7s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.9s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END C=20.0, class_weight=balanced, degree=5, gamma=auto, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-31 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-31.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-31.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-31 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-31 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-31 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-31 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-31 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-31 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-31 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-31 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-31 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-31 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-31 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-31 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-31 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-31 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-31 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-31 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-31 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-31\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=SVC(random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: array([ 0.1       ,  2.31111111,  4.52222222,  6.73333333,  8.94444444,\n",
       "       11.15555556, 13.36666667, 15.57777778, 17.78888889, 20.        ]),\n",
       "                         &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;degree&#x27;: [2, 3, 4, 5], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;]},\n",
       "             scoring=&#x27;recall&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" ><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">SVC(random_state=42)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;C&#x27;: array([ 0.1  ... 20.        ]), &#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;], &#x27;degree&#x27;: [2, 3, ...], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;recall&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">StratifiedKFo... shuffle=True)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: SVC</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>SVC(C=np.float64(0.1), class_weight=&#x27;balanced&#x27;, degree=5, kernel=&#x27;poly&#x27;,\n",
       "    random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Regularization parameter. The strength of the regularization is<br>inversely proportional to C. Must be strictly positive. The penalty<br>is a squared l2 penalty. For an intuitive visualization of the effects<br>of scaling the regularization parameter C, see<br>:ref:`sphx_glr_auto_examples_svm_plot_svm_scale_c.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">np.float64(0.1)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('kernel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=kernel,-%7B%27linear%27%2C%20%27poly%27%2C%20%27rbf%27%2C%20%27sigmoid%27%2C%20%27precomputed%27%7D%20or%20callable%2C%20%20%20%20%20%20%20%20%20%20default%3D%27rbf%27\">\n",
       "            kernel\n",
       "            <span class=\"param-doc-description\">kernel: {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable,          default='rbf'<br><br>Specifies the kernel type to be used in the algorithm. If<br>none is given, 'rbf' will be used. If a callable is given it is used to<br>pre-compute the kernel matrix from data matrices; that matrix should be<br>an array of shape ``(n_samples, n_samples)``. For an intuitive<br>visualization of different kernel types see<br>:ref:`sphx_glr_auto_examples_svm_plot_svm_kernels.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;poly&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('degree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=degree,-int%2C%20default%3D3\">\n",
       "            degree\n",
       "            <span class=\"param-doc-description\">degree: int, default=3<br><br>Degree of the polynomial kernel function ('poly').<br>Must be non-negative. Ignored by all other kernels.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=gamma,-%7B%27scale%27%2C%20%27auto%27%7D%20or%20float%2C%20default%3D%27scale%27\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: {'scale', 'auto'} or float, default='scale'<br><br>Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.<br><br>- if ``gamma='scale'`` (default) is passed then it uses<br>  1 / (n_features * X.var()) as value of gamma,<br>- if 'auto', uses 1 / n_features<br>- if float, must be non-negative.<br><br>.. versionchanged:: 0.22<br>   The default value of ``gamma`` changed from 'auto' to 'scale'.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;scale&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('coef0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=coef0,-float%2C%20default%3D0.0\">\n",
       "            coef0\n",
       "            <span class=\"param-doc-description\">coef0: float, default=0.0<br><br>Independent term in kernel function.<br>It is only significant in 'poly' and 'sigmoid'.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shrinking',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=shrinking,-bool%2C%20default%3DTrue\">\n",
       "            shrinking\n",
       "            <span class=\"param-doc-description\">shrinking: bool, default=True<br><br>Whether to use the shrinking heuristic.<br>See the :ref:`User Guide <shrinking_svm>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('probability',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=probability,-bool%2C%20default%3DFalse\">\n",
       "            probability\n",
       "            <span class=\"param-doc-description\">probability: bool, default=False<br><br>Whether to enable probability estimates. This must be enabled prior<br>to calling `fit`, will slow down that method as it internally uses<br>5-fold cross-validation, and `predict_proba` may be inconsistent with<br>`predict`. Read more in the :ref:`User Guide <scores_probabilities>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=tol,-float%2C%20default%3D1e-3\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-3<br><br>Tolerance for stopping criterion.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cache_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=cache_size,-float%2C%20default%3D200\">\n",
       "            cache_size\n",
       "            <span class=\"param-doc-description\">cache_size: float, default=200<br><br>Specify the size of the kernel cache (in MB).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Set the parameter C of class i to class_weight[i]*C for<br>SVC. If not given, all classes are supposed to have<br>weight one.<br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>Enable verbose output. Note that this setting takes advantage of a<br>per-process runtime setting in libsvm that, if enabled, may not work<br>properly in a multithreaded context.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=max_iter,-int%2C%20default%3D-1\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=-1<br><br>Hard limit on iterations within solver, or -1 for no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decision_function_shape',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=decision_function_shape,-%7B%27ovo%27%2C%20%27ovr%27%7D%2C%20default%3D%27ovr%27\">\n",
       "            decision_function_shape\n",
       "            <span class=\"param-doc-description\">decision_function_shape: {'ovo', 'ovr'}, default='ovr'<br><br>Whether to return a one-vs-rest ('ovr') decision function of shape<br>(n_samples, n_classes) as all other classifiers, or the original<br>one-vs-one ('ovo') decision function of libsvm which has shape<br>(n_samples, n_classes * (n_classes - 1) / 2). However, note that<br>internally, one-vs-one ('ovo') is always used as a multi-class strategy<br>to train models; an ovr matrix is only constructed from the ovo matrix.<br>The parameter is ignored for binary classification.<br><br>.. versionchanged:: 0.19<br>    decision_function_shape is 'ovr' by default.<br><br>.. versionadded:: 0.17<br>   *decision_function_shape='ovr'* is recommended.<br><br>.. versionchanged:: 0.17<br>   Deprecated *decision_function_shape='ovo' and None*.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;ovr&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('break_ties',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=break_ties,-bool%2C%20default%3DFalse\">\n",
       "            break_ties\n",
       "            <span class=\"param-doc-description\">break_ties: bool, default=False<br><br>If true, ``decision_function_shape='ovr'``, and number of classes > 2,<br>:term:`predict` will break ties according to the confidence values of<br>:term:`decision_function`; otherwise the first class among the tied<br>classes is returned. Please note that breaking ties comes at a<br>relatively high computational cost compared to a simple predict. See<br>:ref:`sphx_glr_auto_examples_svm_plot_svm_tie_breaking.py` for an<br>example of its usage with ``decision_function_shape='ovr'``.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.svm.SVC.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the pseudo random number generation for shuffling the data for<br>probability estimates. Ignored when `probability` is False.<br>Pass an int for reproducible output across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-31');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=SVC(random_state=42),\n",
       "             param_grid={'C': array([ 0.1       ,  2.31111111,  4.52222222,  6.73333333,  8.94444444,\n",
       "       11.15555556, 13.36666667, 15.57777778, 17.78888889, 20.        ]),\n",
       "                         'class_weight': [None, 'balanced'],\n",
       "                         'degree': [2, 3, 4, 5], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cb1d3b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average best performance on validation led to a recall of  0.7915032679738563\n",
      "And the params responsable for this are  {'C': np.float64(0.1), 'class_weight': 'balanced', 'degree': 5, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print('the average best performance on validation led to a recall of ', grid_search_svc.best_score_)\n",
    "print('And the params responsable for this are ', grid_search_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f15c00ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " On the test datset , the performance of the best svm is given by :\n",
      "      recall = 0.6440677966101694\n",
      "      precison = 0.3275862068965517\n",
      "      auc = 0.7367121935165377\n"
     ]
    }
   ],
   "source": [
    "best_svm = grid_search_svc.best_estimator_\n",
    "\n",
    "best_svm.probability= True\n",
    "best_svm.fit(X=X_train, y = y_train)\n",
    "# normally we don't need to ddo a fit again \n",
    "\n",
    "y_predicted_svm =  best_svm.predict(X_test)\n",
    "y_proba_SVM = best_svm.predict_proba(X_test)[:,1]\n",
    "\n",
    "auc_svm = roc_auc_score(y_test, y_proba_SVM)\n",
    "recall_svm = recall_score(y_test,y_predicted_svm)\n",
    "precision_svm = precision_score(y_test,y_predicted_svm)\n",
    "mse_svm = mean_squared_error(y_test, y_predicted_svm)\n",
    "\n",
    "print(f''' On the test datset , the performance of the best svm is given by :\n",
    "      recall = {recall_svm}\n",
    "      precison = {precision_svm}\n",
    "      auc = {auc_svm}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "46ed3ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification report of the svm model after gridSearch is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.75      0.82       309\n",
      "           1       0.33      0.64      0.43        59\n",
      "\n",
      "    accuracy                           0.73       368\n",
      "   macro avg       0.62      0.70      0.63       368\n",
      "weighted avg       0.82      0.73      0.76       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_performances.loc['SVM'] = (recall_svm, auc_svm, mse_svm)\n",
    "\n",
    "print('The classification report of the svm model after gridSearch is \\n', classification_report(y_test,y_predicted_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "86ca9a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_svm = pd.DataFrame(confusion_matrix(y_test, y_predicted_svm))\n",
    "\n",
    "sns.heatmap(confusion_matrix_svm , annot= True , cmap='YlGnBu', fmt ='g')\n",
    "plt.title('Confusion matrix of SVM best model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8eafe",
   "metadata": {},
   "source": [
    "### Result Analysis\n",
    "\n",
    "For SVM, it is very famous as a classification model, despite being old, it has always proved his efficiency against complex and high dimensional datasets.\n",
    "\n",
    "In the very first beginning, svm showed some promisisng results using a very naive model by only precising a linear kernel ( the default is rbf ), and adding class_weight= 'balanced' to take into consideration the imbalanced datased and add more penalty on missclassified points from the minority classes. The result was an average recall of 0.75 \n",
    "\n",
    "With such good performance right from the beginning , i decided to dive deep and explore a combination of parameters that would optimize the performance inclusing a variety of kernel types , a wide range of 'C' values to test hard vs soft margins and different values of gamma  ( rbf ) and degree ( polynomial )\n",
    "\n",
    "To my surprise the best perfomance corresponds to the following combination of params:\n",
    "\n",
    "    C=0.1 a very low C corresponds to a wider margin \n",
    "\n",
    "    'kernel'= 'poly' for no particcular reason i was expecting it to be rbf \n",
    "\n",
    "    'class_weight': 'balanced' as expected\n",
    "\n",
    "    'degree': 5 as it is the highest degree i allowed during gridsearch, also the more complex the model, the more precise it is but also the more tendencies it has to overfit\n",
    "\n",
    "Regarding the performance of the models, it does actually perform well on the test dataset , the performance is surely lower than the avg training dataset since it's data the model has never seen before.\n",
    "\n",
    "    RECALL : 0.64\n",
    "\n",
    "    AUC : 0.74\n",
    "\n",
    "    PRECISION : 0.33\n",
    "\n",
    "Again similar to all the previous models, when we take a look at the classification report, the models excels at predicting the current employers instead of of the churning ones since the they are a minority, however the recall is comparable which is satisfying.\n",
    "\n",
    "The confusion matrix shows as an  important thing which is : the high recall is justified by the fact that we catch 38 out of 59 churning person, however regarding the current employees that does not intend to leave wemake a lot of mistakes predicting 78 of them as attrition ( out of 309 ) which is really high and justify the low value of the precision !!!\n",
    "\n",
    "In the cas of svm and the following model XGBOOST , i won't do a threshold tuning  because i don't quit see the imporatnce unless it's the final model i'm going to keep "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f21aa",
   "metadata": {},
   "source": [
    "## XGBOOST\n",
    "\n",
    "XGboost had a poor avg performance at the first try but due to its reputation, i decided to give him the benefit of the doubt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0cb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18b0dc84",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d713ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_performances.to_csv('best_performances.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
